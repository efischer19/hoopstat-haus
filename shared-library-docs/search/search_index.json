{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hoopstat Haus Shared Libraries Documentation","text":"<p>Welcome to the official documentation for Hoopstat Haus shared Python libraries. This documentation provides comprehensive API references, usage examples, and best practices for using our shared libraries across different applications.</p>"},{"location":"#overview","title":"Overview","text":"<p>The Hoopstat Haus project uses a monorepo structure with shared libraries located in the <code>/libs/</code> directory. These libraries provide common functionality that can be reused across multiple applications, following the DRY (Don't Repeat Yourself) principle.</p>"},{"location":"#available-libraries","title":"Available Libraries","text":""},{"location":"#core-libraries","title":"Core Libraries","text":"<ul> <li>hoopstat-config - Standardized configuration management</li> <li>hoopstat-data - Data processing utilities for basketball statistics</li> <li>hoopstat-observability - Logging and monitoring utilities</li> </ul>"},{"location":"#utility-libraries","title":"Utility Libraries","text":"<ul> <li>example-math-utils - Example math utilities (demonstration)</li> <li>hoopstat-mock-data - Mock data generation for testing</li> <li>hoopstat-e2e-testing - End-to-end testing utilities</li> <li>ingestion - Data ingestion utilities</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To use any shared library in your application:</p> <ol> <li> <p>Add it to your <code>pyproject.toml</code> dependencies:    <pre><code>[tool.poetry.dependencies]\nhoopstat-config = {path = \"../libs/hoopstat-config\", develop = true}\n</code></pre></p> </li> <li> <p>Import and use in your code:    <pre><code>from hoopstat_config import ConfigManager\n\nconfig = ConfigManager()\n</code></pre></p> </li> </ol>"},{"location":"#development-philosophy","title":"Development Philosophy","text":"<p>All shared libraries follow the Hoopstat Haus Development Philosophy:</p> <ul> <li>Code is for Humans First - Clear, readable, well-documented code</li> <li>Favor Simplicity - Static-first design with minimal complexity</li> <li>Confidence Through Testing - Comprehensive automated tests</li> <li>Clean Commit History - Atomic commits with descriptive messages</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>For information on contributing to shared libraries, see:</p> <ul> <li>Contributing Guidelines</li> <li>Shared Library Versioning</li> <li>Local Development Dependencies</li> </ul>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Check the API documentation for specific library usage</li> <li>Review usage examples in the library documentation</li> <li>See integration tests for real-world usage patterns</li> <li>Refer to the development documentation for advanced topics</li> </ul>"},{"location":"BUILD_ORCHESTRATION/","title":"Build and Test Orchestration","text":"<p>This document describes the enhanced CI/CD pipeline that validates shared library compatibility and handles deployment requirements appropriately.</p>"},{"location":"BUILD_ORCHESTRATION/#overview","title":"Overview","text":"<p>The CI pipeline has been enhanced to support the monorepo structure with shared libraries (<code>/libs</code>) and applications (<code>/apps</code>). It provides comprehensive testing while ensuring that deployment requirements are only enforced where appropriate.</p>"},{"location":"BUILD_ORCHESTRATION/#pipeline-structure","title":"Pipeline Structure","text":""},{"location":"BUILD_ORCHESTRATION/#1-change-detection-detect-changes","title":"1. Change Detection (<code>detect-changes</code>)","text":"<ul> <li>Detects changes in both <code>/apps</code> and <code>/libs</code> directories</li> <li>Creates dynamic build matrices for changed components</li> <li>Outputs separate matrices for applications and libraries</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#2-library-testing-test-libraries","title":"2. Library Testing (<code>test-libraries</code>)","text":"<ul> <li>Triggers: When changes detected in <code>/libs</code></li> <li>Tests: Format, lint, and unit tests for each changed library</li> <li>No Docker requirement: Libraries are not deployable and don't need containerization</li> <li>Validation: Ensures shared libraries are ready for consumption by applications</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#3-application-testing-test-applications","title":"3. Application Testing (<code>test-applications</code>)","text":"<ul> <li>Triggers: When changes detected in <code>/apps</code></li> <li>Tests: Format, lint, and unit tests for each changed application</li> <li>Conditional Docker builds: Based on application type</li> <li>Deployable apps: Must have Dockerfile, Docker build required</li> <li>Utility tools: No Dockerfile required, skips Docker build</li> <li>Smart detection: Automatically determines build context for apps with shared library dependencies</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#4-integration-testing-test-integration","title":"4. Integration Testing (<code>test-integration</code>)","text":"<ul> <li>Triggers: When both apps and libraries have changes</li> <li>Purpose: Validates that applications work correctly with updated shared libraries</li> <li>Process: Re-runs application tests with updated library dependencies</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#application-types","title":"Application Types","text":""},{"location":"BUILD_ORCHESTRATION/#deployable-applications","title":"Deployable Applications","text":"<ul> <li>Characteristics: Intended for production deployment</li> <li>Requirements: Must have a <code>Dockerfile</code></li> <li>CI Behavior: </li> <li>Standard testing (format, lint, test)</li> <li>Docker build validation</li> <li>Build context automatically adjusted for shared library dependencies</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#utility-applications","title":"Utility Applications","text":"<ul> <li>Characteristics: Tools, scripts, or non-deployable utilities</li> <li>Requirements: No <code>Dockerfile</code> needed</li> <li>CI Behavior:</li> <li>Standard testing (format, lint, test)</li> <li>Docker build skipped</li> <li>Marked as utility in CI output</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#shared-library-dependencies","title":"Shared Library Dependencies","text":"<p>When applications depend on shared libraries:</p> <ol> <li>Detection: CI automatically detects local library dependencies in <code>pyproject.toml</code></li> <li>Build Context: Docker builds are executed from repository root to include library code</li> <li>Integration Testing: Ensures apps work with updated library versions</li> </ol>"},{"location":"BUILD_ORCHESTRATION/#example-dependency-declaration","title":"Example Dependency Declaration","text":"<pre><code>[tool.poetry.dependencies]\npython = \"^3.12\"\nmy-shared-lib = {path = \"../../libs/my-shared-lib\", develop = true}\n</code></pre>"},{"location":"BUILD_ORCHESTRATION/#cicd-workflow-benefits","title":"CI/CD Workflow Benefits","text":""},{"location":"BUILD_ORCHESTRATION/#clear-failure-attribution","title":"Clear Failure Attribution","text":"<ul> <li>Library failures: Isolated to library testing jobs</li> <li>Application failures: Separated by app type (deployable vs utility)</li> <li>Integration failures: Clearly identify app-library compatibility issues</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#efficient-resource-usage","title":"Efficient Resource Usage","text":"<ul> <li>Selective testing: Only test changed components</li> <li>Conditional Docker: Only build containers when needed</li> <li>Parallel execution: Libraries and applications test in parallel</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#deployment-readiness","title":"Deployment Readiness","text":"<ul> <li>Deployable apps: Validated with Docker builds</li> <li>Utility tools: Tested for functionality without deployment overhead</li> <li>Shared libraries: Validated independently and through integration</li> </ul>"},{"location":"BUILD_ORCHESTRATION/#error-scenarios","title":"Error Scenarios","text":""},{"location":"BUILD_ORCHESTRATION/#missing-dockerfile-for-deployable-app","title":"Missing Dockerfile for Deployable App","text":"<pre><code>\u274c Deployable application my-app is missing required Dockerfile\n</code></pre>"},{"location":"BUILD_ORCHESTRATION/#utility-app-expected-behavior","title":"Utility App (Expected Behavior)","text":"<pre><code>\ud83d\udee0\ufe0f Application my-tool is a utility/tool (no Dockerfile required)\n\u2705 Utility/tool application validated successfully\n</code></pre>"},{"location":"BUILD_ORCHESTRATION/#library-failure","title":"Library Failure","text":"<pre><code>\u274c Library example-math-utils failed format check\n\ud83d\udce6 Library is NOT ready for use by applications\n</code></pre>"},{"location":"BUILD_ORCHESTRATION/#integration-failure","title":"Integration Failure","text":"<pre><code>\u274c Integration testing failed for example-calculator-app\n\ud83d\udd17 Application does NOT work correctly with updated shared libraries\n</code></pre>"},{"location":"BUILD_ORCHESTRATION/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Deployment markers: Optional <code>pyproject.toml</code> metadata to explicitly mark deployable vs utility apps</li> <li>Library versioning: Automatic version bumping and compatibility checking</li> <li>Dependency analysis: Automatically test downstream applications when libraries change</li> <li>Security scanning: Container vulnerability assessment for deployable applications</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to Hoopstat Haus","text":"<p>First off, thank you for your interest in Hoopstat Haus! I'm excited you're here.</p> <p>This project is currently in a very early and experimental stage. My primary goal is to use it as a personal learning ground to explore AI-driven software development and build my own skills.</p> <p>That said, I'm open to collaboration, even if the process looks a little different for now.</p>"},{"location":"CONTRIBUTING/#our-current-development-workflow","title":"Our Current Development Workflow","text":"<p>To stay true to the project's mission, <code>hoopstat-haus</code> follows a specific, AI-assisted workflow:</p> <ol> <li>An Issue is created, either by me or a contributor, that clearly defines a bug or a feature.</li> <li>An AI assistant (like GitHub Copilot) is used to generate the code to address the issue. This results in a Pull Request.</li> <li>The PR is then reviewed, tested, and merged by me.</li> </ol> <p>This unique process is the core of the experiment.</p>"},{"location":"CONTRIBUTING/#how-you-can-help-right-now","title":"How You Can Help Right Now","text":"<p>While I'm not actively seeking code contributions from external developers at this time, there are several incredibly valuable ways you can contribute:</p>"},{"location":"CONTRIBUTING/#report-bugs-or-suggest-features","title":"\ud83d\udc1b Report Bugs or Suggest Features","text":"<p>This is the most helpful way to contribute. If you find a bug, have an idea for a feature, or think something could be improved, please open an issue! Clear issues are the starting point for the entire AI workflow.</p>"},{"location":"CONTRIBUTING/#provide-feedback","title":"\ud83d\udcac Provide Feedback","text":"<p>Have thoughts on the project's direction, architecture, or even the AI-driven process itself? Feel free to open an issue to start a discussion. I'd love to hear your perspective.</p>"},{"location":"CONTRIBUTING/#improve-documentation","title":"\ud83d\udcd6 Improve Documentation","text":"<p>If you find a typo, feel something is unclear in the <code>README</code> or other documents, or have a question that could be answered in the docs, please let me know by opening an issue.</p>"},{"location":"CONTRIBUTING/#what-about-code-contributions","title":"What About Code Contributions?","text":"<p>For now, I'm handling the code generation and merging myself as part of the experiment. This helps me maintain a consistent \"voice\" in the code and focus on the AI-centric workflow.</p> <p>As the project matures, this process will likely evolve. Thank you for your understanding!</p>"},{"location":"CONTRIBUTING/#python-development-environment","title":"Python Development Environment","text":""},{"location":"CONTRIBUTING/#setting-up-a-new-python-project","title":"Setting Up a New Python Project","text":"<p>All Python applications in Hoopstat Haus follow a standard structure and tooling approach. To create a new Python project:</p> <ol> <li> <p>Copy the template: <pre><code>cp -r templates/python-app-template apps/your-new-app\ncd apps/your-new-app\n</code></pre></p> </li> <li> <p>Update project configuration:    Edit <code>pyproject.toml</code> to update:</p> </li> <li>Project name (change from \"python-app-template\")</li> <li>Description and authors</li> <li> <p>Package name in the <code>packages</code> field</p> </li> <li> <p>Install dependencies: <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Verify setup: <pre><code>poetry run start    # Should run the hello world app\npoetry run test     # Should run and pass all tests\npoetry run lint     # Should show no linting errors\npoetry run format   # Should format the code\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#development-workflow-for-python-projects","title":"Development Workflow for Python Projects","text":"<p>All Python projects use the same standard commands:</p>"},{"location":"CONTRIBUTING/#standard-scripts","title":"Standard Scripts","text":"<ul> <li><code>poetry run start</code> - Run the application</li> <li><code>poetry run test</code> - Run tests with pytest</li> <li><code>poetry run lint</code> - Run linting with Ruff</li> <li><code>poetry run format</code> - Format code with Black</li> </ul>"},{"location":"CONTRIBUTING/#development-commands","title":"Development Commands","text":"<pre><code># Install/update dependencies\npoetry install\npoetry add package-name              # Add runtime dependency\npoetry add --group dev package-name  # Add development dependency\n\n# Run application directly\npoetry run python -m app.main\n\n# Test with coverage\npoetry run pytest --cov=app\n\n# Fix linting issues automatically\npoetry run ruff check --fix .\n\n# Check formatting without changing files\npoetry run black --check .\n</code></pre>"},{"location":"CONTRIBUTING/#docker-usage","title":"Docker Usage","text":"<pre><code># Build development image\ndocker build --target development -t your-app:dev .\n\n# Build production image  \ndocker build --target production -t your-app:prod .\n\n# Run containers\ndocker run -it your-app:dev      # Development\ndocker run your-app:prod         # Production\n</code></pre>"},{"location":"CONTRIBUTING/#code-quality-standards","title":"Code Quality Standards","text":"<p>Before committing any Python code:</p> <ol> <li> <p>Run all checks: <pre><code>poetry run format   # Format code\npoetry run lint     # Check for issues\npoetry run test     # Run tests\n</code></pre></p> </li> <li> <p>Follow the patterns:</p> </li> <li>Use type hints on function signatures</li> <li>Add docstrings to public functions and classes</li> <li>Write tests for new functionality</li> <li> <p>Keep functions simple and focused</p> </li> <li> <p>Project structure: <pre><code>your-app/\n\u251c\u2500\u2500 app/              # Application source code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py       # Entry point\n\u2502   \u2514\u2500\u2500 scripts.py    # Development scripts\n\u251c\u2500\u2500 tests/            # Test files\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 test_*.py\n\u251c\u2500\u2500 Dockerfile        # Multi-stage Docker build\n\u251c\u2500\u2500 pyproject.toml    # Poetry configuration\n\u2514\u2500\u2500 README.md\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Finally, all participants are expected to follow our Code of Conduct. Please be respectful and considerate in all your interactions.</p>"},{"location":"DEVELOPMENT_PHILOSOPHY/","title":"Development Philosophy &amp; Craftsmanship","text":"<p>This document outlines the core principles that guide all development within the <code>hoopstat-haus</code> project. As an AI contributor, you are expected to understand and adhere to these principles in all generated code, commits, and pull requests.</p> <p>Our guiding star is a quote from the essay Programming Sucks: \"All code is bad\"</p> <p>We write efficient, clear, maintainable code to be kind to our future selves and collaborators.</p>"},{"location":"DEVELOPMENT_PHILOSOPHY/#1-code-is-for-humans-first","title":"1. Code is for Humans First","text":"<p>Code's primary audience is not the computer, but the human developers who will read, debug, and maintain it.</p> <ul> <li>Clarity Over Cleverness: The code must be simple, readable, and easy to understand. Avoid obscure language features or overly complex one-liners.</li> <li>Meaningful Naming: Variables, functions, and classes must have descriptive names that reveal their intent.</li> <li>Comments Explain Why, Not What: Use comments to explain complex logic or the reasoning behind a design decision, not to state what the code is obviously doing.</li> </ul>"},{"location":"DEVELOPMENT_PHILOSOPHY/#2-favor-simplicity-static-first-design","title":"2. Favor Simplicity &amp; Static-First Design","text":"<p>Complexity is the primary enemy of sustainable software. We aggressively pursue simplicity and seek to minimize moving parts wherever possible.</p> <ul> <li>Static Over Dynamic: We prefer static, build-time solutions over dynamic, run-time ones. This reduces the cognitive load and potential for run-time errors.</li> <li>YAGNI (You Ain't Gonna Need It): Do not implement features or add abstractions for speculative future use cases. Solve the problem at hand and no more.</li> <li>Code is a Liability: Every line of code adds to the project's maintenance burden. The goal is to solve the problem with the least amount of code possible.</li> </ul>"},{"location":"DEVELOPMENT_PHILOSOPHY/#3-the-main-branch-is-sacred","title":"3. The <code>main</code> Branch is Sacred","text":"<p>The <code>main</code> branch is the source of truth and must always be in a deployable state. Its integrity is paramount.</p> <ul> <li>Always Deployable: A commit to <code>main</code> means it is tested, reviewed, and ready for production.</li> <li>Fix-Forward, Never Rewind: The history of the <code>main</code> branch must never be rewritten. There are no <code>force-pushes</code>. If a mistake is made, it will be corrected with a new commit or a revert, preserving the historical record.</li> <li>PRs are the Only Gateway: All new commits arrive on <code>main</code> through Pull Requests that have passed all required automated checks and a human review.</li> </ul>"},{"location":"DEVELOPMENT_PHILOSOPHY/#4-confidence-through-automated-testing","title":"4. Confidence Through Automated Testing","text":"<p>Automated tests are the non-negotiable foundation of our confidence. They are what allow us to refactor and build new features without fear.</p> <ul> <li>Test What Matters: We are not dogmatic about the type of tests (unit, integration, E2E, etc.). What is critical is that key functionality is covered by some form of reliable, automated testing.</li> <li>Tests as Living Documentation: Well-written tests should clearly demonstrate how a piece of code is intended to be used and are often the best form of documentation.</li> <li>Coverage is a Goal, Not a Dogma: We aim for good test coverage but focus on testing critical paths and complex logic rather than chasing a meaningless 100% metric.</li> </ul>"},{"location":"DEVELOPMENT_PHILOSOPHY/#5-leave-the-code-better-than-you-found-it","title":"5. Leave the Code Better Than You Found It","text":"<p>We embrace the \"Boy Scout Rule.\" Any time you touch a file, you are responsible for leaving it in a better state.</p> <ul> <li>Incremental Refactoring: If you encounter unclear code or a minor issue while working on a task, clean it up as part of your work.</li> <li>Address Technical Debt: Do not introduce new technical debt. If existing debt must be addressed to complete your task, do so in a separate, clearly labeled commit.</li> </ul>"},{"location":"DEVELOPMENT_PHILOSOPHY/#6-commit-hygiene-is-non-negotiable","title":"6. Commit Hygiene is Non-Negotiable","text":"<p>A clean commit history is a readable story of the project's evolution.</p> <ul> <li>Atomic Commits: Each commit on <code>main</code> must represent a single, logical change. Iterative progress commits are fine on branches, but should be squashed into a single \"mergeable\" commit before or during PR review.</li> <li>Descriptive Commit Messages: Follow the conventional commit message format. The subject line should be a short, imperative summary, and the body should provide context.</li> </ul>"},{"location":"DOCUMENTATION_README/","title":"Automated Documentation Generation","text":"<p>This directory contains the automated documentation generation system for Hoopstat Haus shared libraries.</p>"},{"location":"DOCUMENTATION_README/#overview","title":"Overview","text":"<p>The documentation system automatically generates API documentation from docstrings in shared libraries and builds a static website using MkDocs. This ensures that documentation stays up-to-date with code changes and provides a centralized location for discovering and understanding shared library functionality.</p>"},{"location":"DOCUMENTATION_README/#features","title":"Features","text":"<ul> <li>Automatic API Documentation: Extracts docstrings from all shared libraries in <code>/libs/</code></li> <li>Usage Examples: Includes examples from docstring content</li> <li>Type Hints: Displays function signatures with type annotations</li> <li>Search Functionality: Full-text search across all documentation</li> <li>Mobile-Friendly: Responsive design that works on all devices</li> <li>GitHub Integration: Automatically updates documentation on library changes</li> </ul>"},{"location":"DOCUMENTATION_README/#structure","title":"Structure","text":"<pre><code>docs-src/               # Source documentation files\n\u251c\u2500\u2500 index.md           # Main documentation page\n\u251c\u2500\u2500 libraries/         # Generated library documentation\n\u2502   \u251c\u2500\u2500 index.md      # Libraries overview\n\u2502   \u2514\u2500\u2500 *.md          # Individual library docs (auto-generated)\n\u251c\u2500\u2500 *.md              # Development guides and documentation\n\u2514\u2500\u2500 DEVELOPMENT_PHILOSOPHY.md  # Copied from /meta/\n\nmkdocs.yml             # MkDocs configuration\ndocs-requirements.txt  # Python dependencies for docs\nsite/                  # Built documentation (ignored by git)\n</code></pre>"},{"location":"DOCUMENTATION_README/#usage","title":"Usage","text":""},{"location":"DOCUMENTATION_README/#building-documentation-locally","title":"Building Documentation Locally","text":"<ol> <li> <p>Install dependencies:    <pre><code>pip install -r docs-requirements.txt\n</code></pre></p> </li> <li> <p>Generate and build documentation:    <pre><code>./scripts/build-docs.sh\n</code></pre></p> </li> <li> <p>Serve documentation locally:    <pre><code>mkdocs serve\n</code></pre></p> </li> </ol> <p>The documentation will be available at http://localhost:8000</p>"},{"location":"DOCUMENTATION_README/#scripts","title":"Scripts","text":"<ul> <li><code>scripts/generate-docs.py</code>: Extracts docstrings and generates library documentation</li> <li><code>scripts/build-docs.sh</code>: Complete build process (generate + build)</li> <li><code>scripts/check-docs.sh</code>: Validates documentation completeness</li> </ul>"},{"location":"DOCUMENTATION_README/#automatic-updates","title":"Automatic Updates","text":"<p>Documentation is automatically updated when:</p> <ul> <li>Code changes in any shared library (<code>libs/**</code>)</li> <li>Documentation source changes (<code>docs-src/**</code>)</li> <li>Documentation configuration changes (<code>mkdocs.yml</code>)</li> <li>Documentation scripts change (<code>scripts/generate-docs.py</code>, <code>scripts/build-docs.sh</code>)</li> </ul> <p>The GitHub Actions workflow: 1. Builds documentation on every PR to validate changes 2. Deploys documentation to GitHub Pages on main branch pushes</p>"},{"location":"DOCUMENTATION_README/#adding-documentation-for-new-libraries","title":"Adding Documentation for New Libraries","text":"<p>When you create a new shared library:</p> <ol> <li> <p>Ensure your library has comprehensive docstrings following Google style:    <pre><code>def my_function(param: str) -&gt; bool:\n    \"\"\"\n    Brief description of the function.\n\n    Longer description if needed.\n\n    Args:\n        param: Description of the parameter.\n\n    Returns:\n        Description of the return value.\n\n    Example:\n        &gt;&gt;&gt; my_function(\"test\")\n        True\n    \"\"\"\n</code></pre></p> </li> <li> <p>Run the documentation generation:    <pre><code>./scripts/build-docs.sh\n</code></pre></p> </li> </ol> <p>Documentation will be automatically generated and included in the next build.</p>"},{"location":"DOCUMENTATION_README/#best-practices","title":"Best Practices","text":""},{"location":"DOCUMENTATION_README/#writing-good-docstrings","title":"Writing Good Docstrings","text":"<ul> <li>Use Google-style docstrings for consistency</li> <li>Include type hints in function signatures</li> <li>Provide usage examples in docstrings</li> <li>Document all parameters and return values</li> <li>Explain any exceptions that may be raised</li> </ul>"},{"location":"DOCUMENTATION_README/#example-good-docstring","title":"Example Good Docstring","text":"<pre><code>def process_data(data: List[Dict[str, Any]], validate: bool = True) -&gt; pd.DataFrame:\n    \"\"\"\n    Process raw basketball data into a standardized DataFrame.\n\n    This function takes raw basketball statistics data and converts it into\n    a pandas DataFrame with standardized column names and data types.\n\n    Args:\n        data: List of dictionaries containing raw basketball statistics.\n            Each dictionary should have keys for player name, team, and stats.\n        validate: Whether to validate data integrity before processing.\n            Defaults to True.\n\n    Returns:\n        A pandas DataFrame with standardized basketball statistics.\n        Columns include: player_name, team, points, rebounds, assists.\n\n    Raises:\n        ValueError: If data validation fails and validate=True.\n        KeyError: If required data fields are missing.\n\n    Example:\n        &gt;&gt;&gt; raw_data = [{\"name\": \"LeBron James\", \"team\": \"LAL\", \"pts\": 25}]\n        &gt;&gt;&gt; df = process_data(raw_data)\n        &gt;&gt;&gt; df.columns.tolist()\n        ['player_name', 'team', 'points']\n    \"\"\"\n</code></pre>"},{"location":"DOCUMENTATION_README/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DOCUMENTATION_README/#documentation-not-generating","title":"Documentation Not Generating","text":"<ol> <li>Check that your library has an <code>__init__.py</code> file</li> <li>Ensure docstrings follow Google style format</li> <li>Run <code>./scripts/check-docs.sh</code> to validate completeness</li> <li>Check the build output for any error messages</li> </ol>"},{"location":"DOCUMENTATION_README/#missing-examples","title":"Missing Examples","text":"<p>Examples are automatically extracted from docstrings that contain: - Lines starting with <code>Example:</code> or <code>Examples:</code> - Code blocks using <code>&gt;&gt;&gt;</code> format</p>"},{"location":"DOCUMENTATION_README/#build-failures","title":"Build Failures","text":"<p>Common issues: - Missing dependencies: Install with <code>pip install -r docs-requirements.txt</code> - Python import errors: Ensure libraries can be imported - Markdown syntax errors: Check generated <code>.md</code> files</p>"},{"location":"DOCUMENTATION_README/#configuration","title":"Configuration","text":"<p>The documentation system is configured through:</p> <ul> <li><code>mkdocs.yml</code>: Main MkDocs configuration</li> <li><code>scripts/generate-docs.py</code>: API documentation extraction logic</li> <li><code>.github/workflows/documentation.yml</code>: CI/CD automation</li> </ul> <p>To customize the documentation appearance or behavior, modify these configuration files.</p>"},{"location":"E2E_TESTING/","title":"E2E Pipeline Testing Framework","text":"<p>This document provides comprehensive setup and usage instructions for the localstack-based pipeline testing framework.</p>"},{"location":"E2E_TESTING/#overview","title":"Overview","text":"<p>The E2E testing framework simulates the complete data pipeline flow from bronze \u2192 silver \u2192 gold layers using Localstack S3 simulation. This enables local development and CI testing without requiring actual AWS resources.</p>"},{"location":"E2E_TESTING/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Bronze Layer  \u2502    \u2502  Silver Layer   \u2502    \u2502   Gold Layer    \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 Raw NBA data    \u2502\u2500\u2500\u25b6 \u2502 Cleaned &amp;       \u2502\u2500\u2500\u25b6 \u2502 Business        \u2502\n\u2502 (JSON format)   \u2502    \u2502 normalized      \u2502    \u2502 metrics         \u2502\n\u2502                 \u2502    \u2502 (Parquet)       \u2502    \u2502 (Parquet/JSON)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"E2E_TESTING/#components","title":"Components","text":"<ul> <li>Localstack: AWS S3 simulation for local testing</li> <li>S3TestUtils: Utilities for S3 bucket operations (create, read, write, delete)</li> <li>PipelineTestRunner: Orchestrates the complete pipeline testing</li> <li>LocalstackManager: Manages Localstack container lifecycle</li> <li>Docker Compose: Multi-service orchestration for testing</li> </ul>"},{"location":"E2E_TESTING/#local-development-setup","title":"Local Development Setup","text":""},{"location":"E2E_TESTING/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose</li> <li>Poetry (Python dependency management)</li> <li>Python 3.12+</li> </ul>"},{"location":"E2E_TESTING/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Clone and navigate to the repository: <pre><code>git clone &lt;repository-url&gt;\ncd hoopstat-haus\n</code></pre></p> </li> <li> <p>Start the E2E testing environment: <pre><code>docker compose -f docker-compose.test.yml up --build\n</code></pre></p> </li> <li> <p>Run tests manually (alternative approach): <pre><code>cd libs/hoopstat-e2e-testing\npoetry install\npoetry run pytest -v\n</code></pre></p> </li> </ol>"},{"location":"E2E_TESTING/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Start Localstack for development: <pre><code>docker run --rm -d \\\n  --name localstack-dev \\\n  -p 4566:4566 \\\n  -e SERVICES=s3 \\\n  -e DEBUG=1 \\\n  localstack/localstack:3.8\n</code></pre></p> </li> <li> <p>Run specific tests: <pre><code>cd libs/hoopstat-e2e-testing\npoetry run pytest tests/test_s3_utils.py -v\npoetry run pytest tests/test_pipeline_runner.py -v\n</code></pre></p> </li> <li> <p>Run integration tests: <pre><code>cd testing\npoetry run pytest tests/test_integration_pipeline.py -v\n</code></pre></p> </li> </ol>"},{"location":"E2E_TESTING/#usage-examples","title":"Usage Examples","text":""},{"location":"E2E_TESTING/#basic-s3-operations","title":"Basic S3 Operations","text":"<pre><code>from hoopstat_e2e_testing import S3TestUtils\n\n# Initialize S3 utilities\ns3_utils = S3TestUtils(endpoint_url=\"http://localhost:4566\")\n\n# Create a bucket\ns3_utils.create_bucket(\"my-test-bucket\")\n\n# Upload data\ntest_data = {\"message\": \"Hello, World!\", \"count\": 42}\ns3_utils.put_object(\"my-test-bucket\", \"data/test.json\", test_data)\n\n# Download data\nretrieved_data = s3_utils.get_object(\"my-test-bucket\", \"data/test.json\", \"json\")\nprint(retrieved_data)  # {\"message\": \"Hello, World!\", \"count\": 42}\n\n# Clean up\ns3_utils.delete_bucket(\"my-test-bucket\", delete_objects=True)\n</code></pre>"},{"location":"E2E_TESTING/#complete-pipeline-testing","title":"Complete Pipeline Testing","text":"<pre><code>from hoopstat_e2e_testing import S3TestUtils, PipelineTestRunner\n\n# Initialize components\ns3_utils = S3TestUtils(endpoint_url=\"http://localhost:4566\")\npipeline = PipelineTestRunner(s3_utils, project_name=\"my-test\")\n\n# Run complete pipeline\nsuccess = pipeline.run_full_pipeline(num_teams=4, num_players_per_team=5)\n\nif success:\n    # Verify results\n    verification = pipeline.verify_pipeline_output()\n    print(\"Pipeline verification:\", verification)\n\n    # Clean up\n    pipeline.cleanup_environment()\n</code></pre>"},{"location":"E2E_TESTING/#dataframe-operations","title":"DataFrame Operations","text":"<pre><code>import pandas as pd\nfrom hoopstat_e2e_testing import S3TestUtils\n\ns3_utils = S3TestUtils()\ns3_utils.create_bucket(\"data-bucket\")\n\n# Upload DataFrame as Parquet\ndf = pd.DataFrame({\n    \"player\": [\"LeBron James\", \"Stephen Curry\", \"Kevin Durant\"],\n    \"points\": [25.7, 24.8, 27.1],\n    \"team\": [\"Lakers\", \"Warriors\", \"Nets\"]\n})\n\ns3_utils.put_object(\"data-bucket\", \"stats/players.parquet\", df)\n\n# Download DataFrame\nretrieved_df = s3_utils.get_object(\"data-bucket\", \"stats/players.parquet\", \"dataframe\")\nprint(retrieved_df)\n</code></pre>"},{"location":"E2E_TESTING/#ci-integration","title":"CI Integration","text":"<p>The E2E testing framework integrates with the existing GitHub Actions CI workflow:</p>"},{"location":"E2E_TESTING/#automatic-triggering","title":"Automatic Triggering","text":"<p>Tests run automatically when: - Changes are made to <code>hoopstat-e2e-testing</code>, <code>hoopstat-mock-data</code>, or <code>hoopstat-data</code> libraries - Pull request body contains <code>[e2e]</code> tag - Changes are pushed to the main branch</p>"},{"location":"E2E_TESTING/#manual-triggering","title":"Manual Triggering","text":"<p>Add <code>[e2e]</code> to your pull request description to force E2E tests to run:</p> <pre><code>## Changes\n- Updated data processing logic\n- Fixed bug in player statistics calculation\n\n[e2e] - Run E2E pipeline tests\n</code></pre>"},{"location":"E2E_TESTING/#ci-workflow-steps","title":"CI Workflow Steps","text":"<ol> <li>Environment Setup: Builds Docker containers with all dependencies</li> <li>Localstack Startup: Starts S3 simulation service with health checks</li> <li>Test Execution: Runs complete pipeline tests in isolated environment</li> <li>Result Validation: Verifies bronze \u2192 silver \u2192 gold data flow</li> <li>Cleanup: Removes containers and volumes</li> </ol>"},{"location":"E2E_TESTING/#configuration","title":"Configuration","text":""},{"location":"E2E_TESTING/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>AWS_ENDPOINT_URL</code> <code>http://localhost:4566</code> Localstack endpoint <code>AWS_ACCESS_KEY_ID</code> <code>test</code> Test AWS access key <code>AWS_SECRET_ACCESS_KEY</code> <code>test</code> Test AWS secret key <code>AWS_DEFAULT_REGION</code> <code>us-east-1</code> AWS region for testing"},{"location":"E2E_TESTING/#docker-compose-configuration","title":"Docker Compose Configuration","text":"<p>The <code>docker-compose.test.yml</code> file defines:</p> <ul> <li>Localstack service: S3 simulation with health checks</li> <li>Test runner service: Python environment with all dependencies</li> <li>Network isolation: Dedicated network for test communication</li> <li>Volume management: Temporary storage for test data</li> </ul>"},{"location":"E2E_TESTING/#testing-strategy","title":"Testing Strategy","text":""},{"location":"E2E_TESTING/#test-layers","title":"Test Layers","text":"<ol> <li>Unit Tests: Individual component testing (S3Utils, PipelineRunner)</li> <li>Integration Tests: End-to-end pipeline validation</li> <li>Performance Tests: Large dataset processing validation</li> <li>Data Quality Tests: Cross-layer consistency validation</li> </ol>"},{"location":"E2E_TESTING/#test-data","title":"Test Data","text":"<ul> <li>Mock NBA Data: Realistic team, player, and game statistics</li> <li>Deterministic Generation: Seeded random data for reproducible tests</li> <li>Scalable Volumes: From small test sets to large-scale simulations</li> </ul>"},{"location":"E2E_TESTING/#validation-checks","title":"Validation Checks","text":"<ul> <li>Data Consistency: Record counts match across pipeline layers</li> <li>Schema Compliance: Data structures meet expected formats</li> <li>Business Logic: Statistical calculations are accurate</li> <li>Performance: Processing times meet acceptable thresholds</li> </ul>"},{"location":"E2E_TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"E2E_TESTING/#common-issues","title":"Common Issues","text":"<p>1. Localstack Connection Failed <pre><code># Check if Localstack is running\ncurl http://localhost:4566/health\n\n# Restart Localstack\ndocker compose -f docker-compose.test.yml restart localstack\n</code></pre></p> <p>2. Permission Errors <pre><code># Fix Docker permissions\nsudo chmod 666 /var/run/docker.sock\n\n# Clean up containers\ndocker compose -f docker-compose.test.yml down --volumes\n</code></pre></p> <p>3. Port Conflicts <pre><code># Check port usage\nnetstat -tulpn | grep 4566\n\n# Kill conflicting processes\nsudo fuser -k 4566/tcp\n</code></pre></p> <p>4. Memory Issues <pre><code># Increase Docker memory limit\n# Docker Desktop \u2192 Settings \u2192 Resources \u2192 Memory \u2192 4GB+\n\n# Clean up unused containers\ndocker system prune -f\n</code></pre></p>"},{"location":"E2E_TESTING/#debug-mode","title":"Debug Mode","text":"<p>Enable verbose logging for troubleshooting:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n\nfrom hoopstat_e2e_testing import S3TestUtils\ns3_utils = S3TestUtils()\n# Detailed logs will be displayed\n</code></pre>"},{"location":"E2E_TESTING/#log-analysis","title":"Log Analysis","text":"<p>Check Localstack logs for S3 operations: <pre><code>docker compose -f docker-compose.test.yml logs localstack\n</code></pre></p> <p>Check test runner logs for application errors: <pre><code>docker compose -f docker-compose.test.yml logs test-runner\n</code></pre></p>"},{"location":"E2E_TESTING/#performance-considerations","title":"Performance Considerations","text":""},{"location":"E2E_TESTING/#resource-usage","title":"Resource Usage","text":"<ul> <li>Memory: ~2GB recommended for Docker environment</li> <li>CPU: Tests run in parallel where possible</li> <li>Storage: Temporary data cleaned up automatically</li> <li>Network: Isolated container communication</li> </ul>"},{"location":"E2E_TESTING/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Parallel Execution: Use pytest-xdist for faster test runs</li> <li>Data Caching: Reuse generated mock data between tests</li> <li>Selective Testing: Run only changed components during development</li> <li>Resource Limits: Configure appropriate Docker memory/CPU limits</li> </ol>"},{"location":"E2E_TESTING/#contributing","title":"Contributing","text":""},{"location":"E2E_TESTING/#adding-new-tests","title":"Adding New Tests","text":"<ol> <li>Create test files in <code>libs/hoopstat-e2e-testing/tests/</code></li> <li>Follow existing naming conventions (<code>test_*.py</code>)</li> <li>Use pytest fixtures for setup/teardown</li> <li>Include both positive and negative test cases</li> </ol>"},{"location":"E2E_TESTING/#extending-pipeline","title":"Extending Pipeline","text":"<ol> <li>Add new transformation logic to <code>PipelineTestRunner</code></li> <li>Create corresponding validation methods</li> <li>Update integration tests to cover new functionality</li> <li>Document new features in this README</li> </ol>"},{"location":"E2E_TESTING/#best-practices","title":"Best Practices","text":"<ul> <li>Isolation: Each test should clean up after itself</li> <li>Determinism: Use seeded random data for reproducible results</li> <li>Documentation: Comment complex test scenarios</li> <li>Performance: Avoid unnecessary data generation in tests</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/","title":"AWS ECR Image Management Guide","text":"<p>This document outlines the procedures for managing Docker images in AWS Elastic Container Registry (ECR) for the Hoopstat Haus project.</p>"},{"location":"ECR_IMAGE_MANAGEMENT/#overview","title":"Overview","text":"<p>The project uses AWS ECR to store and manage Docker images built by our CI/CD pipeline. All application containers are stored in a single ECR repository with a standardized tagging strategy.</p>"},{"location":"ECR_IMAGE_MANAGEMENT/#ecr-repository-configuration","title":"ECR Repository Configuration","text":"<ul> <li>Repository Name: <code>hoopstat-haus/prod</code></li> <li>Registry Region: <code>us-east-1</code></li> <li>Image Scanning: Enabled (automatic scan on push)</li> <li>Tag Mutability: MUTABLE (allows tag updates)</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#image-tagging-strategy","title":"Image Tagging Strategy","text":"<p>Images are tagged using the following convention:</p>"},{"location":"ECR_IMAGE_MANAGEMENT/#standard-tags","title":"Standard Tags","text":"<ul> <li><code>{app-name}-{git-sha}</code> - Immutable tag linked to specific commit</li> <li><code>{app-name}-latest</code> - Points to the most recent build of the application</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#examples","title":"Examples","text":"<ul> <li><code>example-calculator-app-a1b2c3d4</code> - Specific commit of calculator app</li> <li><code>example-calculator-app-latest</code> - Latest version of calculator app</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#automatic-image-building-and-pushing","title":"Automatic Image Building and Pushing","text":"<p>Images are automatically built and pushed to ECR when: 1. Code is pushed to the <code>main</code> branch 2. The application has a <code>Dockerfile</code> 3. CI tests pass successfully</p>"},{"location":"ECR_IMAGE_MANAGEMENT/#build-process","title":"Build Process","text":"<ol> <li>Detection: CI detects changed applications with Dockerfiles</li> <li>Testing: Applications are tested for code quality and functionality</li> <li>Building: Docker images are built using multi-stage Dockerfiles</li> <li>Authentication: GitHub Actions authenticates to AWS using OIDC</li> <li>Pushing: Images are tagged and pushed to ECR</li> <li>Scanning: ECR automatically scans images for vulnerabilities</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#deployment-workflow","title":"Deployment Workflow","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#manual-deployment","title":"Manual Deployment","text":"<p>Use the deployment workflow to deploy specific application versions:</p> <pre><code># Via GitHub Actions UI\n1. Go to Actions \u2192 Deploy Applications\n2. Select \"Run workflow\"\n3. Choose application, environment, and image tag\n4. Click \"Run workflow\"\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#automatic-deployment","title":"Automatic Deployment","text":"<p>Applications are automatically deployed when: 1. Code is pushed to <code>main</code> branch 2. Application has deployable changes 3. CI/CD pipeline completes successfully</p>"},{"location":"ECR_IMAGE_MANAGEMENT/#image-lifecycle-management","title":"Image Lifecycle Management","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#automatic-cleanup-policies","title":"Automatic Cleanup Policies","text":"<p>ECR is configured with lifecycle policies to manage costs:</p> <ol> <li>Tagged Images: Keep last 10 images with <code>v</code> prefix tags</li> <li>Untagged Images: Delete images older than 1 day</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#manual-image-management","title":"Manual Image Management","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#list-images","title":"List Images","text":"<pre><code># List all images in the repository\naws ecr describe-images --repository-name hoopstat-haus/prod\n\n# List images for specific application\naws ecr describe-images --repository-name hoopstat-haus/prod \\\n  --query \"imageDetails[?starts_with(imageTag, 'example-calculator-app-')]\"\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#delete-specific-image","title":"Delete Specific Image","text":"<pre><code># Delete by tag\naws ecr batch-delete-image --repository-name hoopstat-haus/prod \\\n  --image-ids imageTag=example-calculator-app-old-version\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#pull-image-locally","title":"Pull Image Locally","text":"<pre><code># Authenticate Docker to ECR\naws ecr get-login-password --region us-east-1 | \\\n  docker login --username AWS --password-stdin {account-id}.dkr.ecr.us-east-1.amazonaws.com\n\n# Pull specific image\ndocker pull {account-id}.dkr.ecr.us-east-1.amazonaws.com/hoopstat-haus/prod:example-calculator-app-latest\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#security-features","title":"Security Features","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#image-scanning","title":"Image Scanning","text":"<ul> <li>Scan on Push: All images are automatically scanned for vulnerabilities</li> <li>Scan Results: View scan results in AWS Console under ECR \u2192 Repository \u2192 Images</li> <li>Integration: CI/CD pipeline can be configured to fail on critical vulnerabilities</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#access-control","title":"Access Control","text":"<ul> <li>GitHub Actions: Uses OIDC for secure authentication without long-lived credentials</li> <li>IAM Policies: Least-privilege access for ECR operations</li> <li>Repository Policies: Configured to allow access only from authorized sources</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#cloudwatch-integration","title":"CloudWatch Integration","text":"<ul> <li>Push Metrics: Automatic metrics for image pushes and pulls</li> <li>Storage Metrics: Monitor repository size and costs</li> <li>Access Logs: Track who accesses which images</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#cost-monitoring","title":"Cost Monitoring","text":"<ul> <li>Lifecycle Policies: Automatic cleanup to control storage costs</li> <li>Usage Tracking: Monitor repository size trends</li> <li>Billing Alerts: Set up alerts for unexpected ECR costs</li> </ul>"},{"location":"ECR_IMAGE_MANAGEMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#common-issues","title":"Common Issues","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#image-push-failures","title":"Image Push Failures","text":"<pre><code># Check AWS credentials\naws sts get-caller-identity\n\n# Verify ECR permissions\naws ecr describe-repositories --repository-names hoopstat-haus/prod\n\n# Check Docker login\ndocker info | grep -i registry\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#image-pull-failures","title":"Image Pull Failures","text":"<pre><code># Verify image exists\naws ecr describe-images --repository-name hoopstat-haus/prod \\\n  --image-ids imageTag=your-app-name-tag\n\n# Check network connectivity\naws ecr get-login-password --region us-east-1\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#authentication-issues","title":"Authentication Issues","text":"<pre><code># Verify GitHub Actions role\naws iam get-role --role-name hoopstat-haus-github-actions\n\n# Check OIDC provider\naws iam list-open-id-connect-providers\n</code></pre>"},{"location":"ECR_IMAGE_MANAGEMENT/#getting-help","title":"Getting Help","text":"<ol> <li>Infrastructure Issues: Check Terraform configuration in <code>infrastructure/main.tf</code></li> <li>CI/CD Issues: Review GitHub Actions logs and workflow files</li> <li>AWS Issues: Check CloudWatch logs and AWS console</li> <li>Application Issues: Review application logs and health checks</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#best-practices","title":"Best Practices","text":""},{"location":"ECR_IMAGE_MANAGEMENT/#development-workflow","title":"Development Workflow","text":"<ol> <li>Local Testing: Always test Docker builds locally before pushing</li> <li>Branch Protection: Use feature branches and PR reviews</li> <li>Image Size: Optimize Dockerfiles for smaller images</li> <li>Security: Regularly review scan results and update base images</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#production-deployment","title":"Production Deployment","text":"<ol> <li>Staging: Test deployments in staging environment first</li> <li>Rollback: Keep previous versions available for quick rollback</li> <li>Monitoring: Monitor application health after deployment</li> <li>Documentation: Update deployment logs and documentation</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Regular Cleanup: Review and clean up unused images</li> <li>Base Images: Use official, minimal base images</li> <li>Multi-stage Builds: Use multi-stage Dockerfiles to reduce image size</li> <li>Lifecycle Policies: Regularly review and update lifecycle policies</li> </ol>"},{"location":"ECR_IMAGE_MANAGEMENT/#related-documentation","title":"Related Documentation","text":"<ul> <li>AWS ECR User Guide</li> <li>Docker Best Practices</li> <li>GitHub Actions with AWS</li> <li>Infrastructure Documentation</li> </ul> <p>Last updated: 2024-07-21 Document version: 1.0</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/","title":"Local Development Dependency Management Guide","text":"<p>This guide explains how to efficiently develop with shared libraries in the Hoopstat Haus monorepo using Poetry's local path dependencies with hot reloading.</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#overview","title":"Overview","text":"<p>The Hoopstat Haus monorepo supports seamless local development between applications and shared libraries using Poetry's local path dependencies. This enables:</p> <ul> <li>Hot reloading: Library changes are immediately available in consuming applications</li> <li>No reinstalls: No need to reinstall packages when developing locally</li> <li>Efficient workflow: Rapid iteration and testing across multiple components</li> </ul>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#quick-start","title":"Quick Start","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#1-add-a-local-dependency","title":"1. Add a Local Dependency","text":"<p>In your application's <code>pyproject.toml</code>, add the shared library as a local path dependency:</p> <pre><code>[tool.poetry.dependencies]\npython = \"^3.12\"\nyour-shared-lib = {path = \"../../libs/your-shared-lib\", develop = true}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code>cd apps/your-app\npoetry install\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#3-use-the-library","title":"3. Use the Library","text":"<pre><code># In your application code\nfrom your_shared_lib import some_function\n\nresult = some_function(data)\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#4-develop-with-hot-reloading","title":"4. Develop with Hot Reloading","text":"<ol> <li>Modify code in <code>libs/your-shared-lib/</code></li> <li>Run your app: <code>poetry run start</code></li> <li>Changes are immediately available!</li> </ol>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#configuration-details","title":"Configuration Details","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#local-path-dependency-syntax","title":"Local Path Dependency Syntax","text":"<pre><code>library-name = {path = \"../../libs/library-name\", develop = true}\n</code></pre> <p>Key components: - <code>path</code>: Relative path from app to library - <code>develop = true</code>: Enables editable installs and hot reloading</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#path-resolution-examples","title":"Path Resolution Examples","text":"<pre><code># From apps/web-dashboard/ to libs/auth-utils/\nauth-utils = {path = \"../../libs/auth-utils\", develop = true}\n\n# From apps/data-pipeline/ to libs/basketball-stats/\nbasketball-stats = {path = \"../../libs/basketball-stats\", develop = true}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#optional-version-constraints","title":"Optional Version Constraints","text":"<p>For production stability, you can add version constraints:</p> <pre><code># Development with version constraint\nmy-lib = {path = \"../../libs/my-lib\", version = \"^1.0.0\", develop = true}\n\n# Production with exact version pinning\nmy-lib = {path = \"../../libs/my-lib\", version = \"=1.2.3\"}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#development-workflow","title":"Development Workflow","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#creating-a-new-shared-library","title":"Creating a New Shared Library","text":"<ol> <li> <p>Create from template: <pre><code>cp -r templates/python-lib-template libs/your-new-lib\ncd libs/your-new-lib\n</code></pre></p> </li> <li> <p>Customize the library:</p> </li> <li>Update <code>pyproject.toml</code> with correct name and description</li> <li>Rename template directories and files</li> <li> <p>Implement your library functions</p> </li> <li> <p>Install and test: <pre><code>poetry install\npoetry run pytest\n</code></pre></p> </li> </ol>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#adding-library-to-application","title":"Adding Library to Application","text":"<ol> <li> <p>Add dependency to app: <pre><code># In apps/your-app/pyproject.toml\nyour-new-lib = {path = \"../../libs/your-new-lib\", develop = true}\n</code></pre></p> </li> <li> <p>Install in app: <pre><code>cd apps/your-app\npoetry lock  # Update lock file\npoetry install\n</code></pre></p> </li> <li> <p>Use in application: <pre><code>from your_new_lib import your_function\n</code></pre></p> </li> </ol>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#hot-reloading-development-cycle","title":"Hot Reloading Development Cycle","text":"<pre><code># 1. Make changes to shared library\nvim libs/my-lib/my_lib/module.py\n\n# 2. Test library directly (optional)\ncd libs/my-lib\npoetry run pytest\n\n# 3. Test in consuming application immediately\ncd apps/my-app\npoetry run start  # Changes are live!\n\n# 4. Run app tests\npoetry run test\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#best-practices","title":"Best Practices","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#1-library-development","title":"1. Library Development","text":"<ul> <li>Keep libraries focused: Each library should have a single, clear purpose</li> <li>Use semantic versioning: Bump versions appropriately for breaking changes</li> <li>Test thoroughly: Libraries should have comprehensive test coverage</li> <li>Document well: Clear documentation and type hints for all public APIs</li> </ul>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#2-dependency-management","title":"2. Dependency Management","text":"<ul> <li>Use <code>develop = true</code> for active development: Enables hot reloading</li> <li>Consider version constraints for production: Pin versions for stability</li> <li>Minimize circular dependencies: Keep dependency graphs simple</li> <li>Group related functionality: Don't create too many small libraries</li> </ul>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#3-development-workflow","title":"3. Development Workflow","text":"<ul> <li>Test library changes in isolation first: Run library tests before testing in apps</li> <li>Use relative imports carefully: Ensure imports work both locally and when installed</li> <li>Keep lock files updated: Run <code>poetry lock</code> when adding new dependencies</li> <li>Document breaking changes: Clearly communicate API changes to app developers</li> </ul>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#common-patterns","title":"Common Patterns","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#pattern-1-utility-library","title":"Pattern 1: Utility Library","text":"<pre><code># libs/data-utils/pyproject.toml\n[tool.poetry]\nname = \"data-utils\"\nversion = \"0.1.0\"\ndescription = \"Common data processing utilities\"\n\n# apps/data-pipeline/pyproject.toml\n[tool.poetry.dependencies]\ndata-utils = {path = \"../../libs/data-utils\", develop = true}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#pattern-2-api-client-library","title":"Pattern 2: API Client Library","text":"<pre><code># libs/nba-api-client/pyproject.toml\n[tool.poetry]\nname = \"nba-api-client\"\nversion = \"1.0.0\"\ndescription = \"NBA API client library\"\n\n# apps/stats-collector/pyproject.toml\n[tool.poetry.dependencies]\nnba-api-client = {path = \"../../libs/nba-api-client\", version = \"^1.0.0\", develop = true}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#pattern-3-multiple-libraries","title":"Pattern 3: Multiple Libraries","text":"<pre><code># apps/web-dashboard/pyproject.toml\n[tool.poetry.dependencies]\npython = \"^3.12\"\nauth-utils = {path = \"../../libs/auth-utils\", develop = true}\nbasketball-stats = {path = \"../../libs/basketball-stats\", develop = true}\ndata-visualization = {path = \"../../libs/data-visualization\", develop = true}\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#troubleshooting","title":"Troubleshooting","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#issue-package-not-found-errors","title":"Issue: \"Package not found\" Errors","text":"<p>Symptoms: Import errors or Poetry can't find the library</p> <p>Solutions: 1. Verify the path is correct:    <pre><code>ls ../../libs/your-lib/pyproject.toml\n</code></pre></p> <ol> <li>Ensure the library has a valid <code>pyproject.toml</code></li> <li>Check that the package name matches between library and dependency declaration</li> </ol>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#issue-changes-not-reflected","title":"Issue: Changes Not Reflected","text":"<p>Symptoms: Library changes don't appear in the application</p> <p>Solutions: 1. Ensure <code>develop = true</code> is set in the dependency 2. Restart Python processes/development servers 3. Check for cached imports in long-running processes</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#issue-version-conflicts","title":"Issue: Version Conflicts","text":"<p>Symptoms: Poetry resolver conflicts when adding dependencies</p> <p>Solutions: 1. Use compatible version ranges: <code>^1.0.0</code> instead of exact versions 2. Update all related libraries to compatible versions 3. Consider using version overrides for development</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#issue-circular-dependencies","title":"Issue: Circular Dependencies","text":"<p>Symptoms: Library A depends on Library B which depends on Library A</p> <p>Solutions: 1. Extract common functionality to a third library 2. Restructure to eliminate circular dependencies 3. Use dependency injection patterns</p>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#testing-shared-libraries","title":"Testing Shared Libraries","text":"<pre><code># .github/workflows/test-libraries.yml\n- name: Test shared libraries\n  run: |\n    for lib in libs/*/; do\n      cd \"$lib\"\n      poetry install\n      poetry run pytest\n      cd ../..\n    done\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#testing-applications-with-local-dependencies","title":"Testing Applications with Local Dependencies","text":"<pre><code># .github/workflows/test-apps.yml\n- name: Test applications\n  run: |\n    for app in apps/*/; do\n      cd \"$app\"\n      poetry install\n      poetry run test\n      cd ../..\n    done\n</code></pre>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#related-documentation","title":"Related Documentation","text":"<ul> <li>Shared Library Versioning Guide</li> <li>Development Philosophy</li> <li>ADR-003: Poetry Dependencies</li> <li>ADR-016: Shared Library Versioning</li> </ul>"},{"location":"LOCAL_DEVELOPMENT_DEPENDENCIES/#examples","title":"Examples","text":"<p>See working examples in the repository:</p> <ul> <li>Library Example: <code>libs/example-math-utils/</code></li> <li>Application Example: <code>apps/example-calculator-app/</code></li> </ul> <p>These demonstrate the complete workflow from library creation to application integration with hot reloading.</p>"},{"location":"SHARED_LIBRARY_VERSIONING/","title":"Shared Library Versioning Guide","text":"<p>This document outlines the versioning strategy for shared libraries in the Hoopstat Haus monorepo, as established in ADR-016.</p>"},{"location":"SHARED_LIBRARY_VERSIONING/#overview","title":"Overview","text":"<p>Shared libraries in the <code>/libs</code> directory follow Semantic Versioning (SemVer) to enable clear dependency management and stable deployments.</p>"},{"location":"SHARED_LIBRARY_VERSIONING/#semantic-versioning-format","title":"Semantic Versioning Format","text":"<p>All shared libraries use the MAJOR.MINOR.PATCH format:</p> <ul> <li>MAJOR: Incremented for breaking changes that require code changes in consuming applications</li> <li>MINOR: Incremented for new features that are backward compatible</li> <li>PATCH: Incremented for bug fixes that are backward compatible</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#examples","title":"Examples","text":"<ul> <li><code>1.0.0</code> \u2192 <code>1.0.1</code>: Bug fix (safe to update)</li> <li><code>1.0.1</code> \u2192 <code>1.1.0</code>: New backward-compatible feature (safe to update) </li> <li><code>1.1.0</code> \u2192 <code>2.0.0</code>: Breaking change (requires code changes in apps)</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#version-management-process","title":"Version Management Process","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#1-initial-library-version","title":"1. Initial Library Version","text":"<p>New libraries start at version <code>0.1.0</code> to indicate pre-release status:</p> <pre><code>[tool.poetry]\nname = \"my-new-library\"\nversion = \"0.1.0\"\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#2-version-bumping-guidelines","title":"2. Version Bumping Guidelines","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#for-bug-fixes-patch","title":"For Bug Fixes (PATCH)","text":"<pre><code># Fix a bug without changing the API\n# 1.0.0 \u2192 1.0.1\npoetry version patch\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#for-new-features-minor","title":"For New Features (MINOR)","text":"<pre><code># Add new functions/classes without breaking existing ones\n# 1.0.1 \u2192 1.1.0\npoetry version minor\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#for-breaking-changes-major","title":"For Breaking Changes (MAJOR)","text":"<pre><code># Change function signatures, remove functions, change behavior\n# 1.1.0 \u2192 2.0.0\npoetry version major\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#3-pre-release-versions","title":"3. Pre-release Versions","text":"<p>For development versions before a stable release:</p> <pre><code># Create a pre-release version\n# 1.0.0 \u2192 1.1.0-alpha.1\npoetry version preminor --next-phase=alpha\n\n# Bump pre-release\n# 1.1.0-alpha.1 \u2192 1.1.0-alpha.2\npoetry version prerelease\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#dependency-management-between-apps-and-libraries","title":"Dependency Management Between Apps and Libraries","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#development-dependencies-recommended","title":"Development Dependencies (Recommended)","text":"<p>For active development, applications should use local path dependencies:</p> <pre><code># In apps/my-app/pyproject.toml\n[tool.poetry.dependencies]\npython = \"^3.12\"\n# Use local path for development\nbasketball-stats = {path = \"../../libs/basketball-stats\", develop = true}\ndata-utils = {path = \"../../libs/data-utils\", develop = true}\n</code></pre> <p>Benefits: - Immediate access to library changes during development - No version management overhead for local development - Supports rapid iteration and testing</p>"},{"location":"SHARED_LIBRARY_VERSIONING/#production-dependencies-optional","title":"Production Dependencies (Optional)","text":"<p>For production stability, applications can pin to specific versions:</p> <pre><code># In apps/my-app/pyproject.toml\n[tool.poetry.dependencies]\npython = \"^3.12\"\n# Pin to specific versions for stability\nbasketball-stats = {path = \"../../libs/basketball-stats\", version = \"^1.2.0\"}\ndata-utils = {path = \"../../libs/data-utils\", version = \"^2.0.0\"}\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#version-constraint-guidelines","title":"Version Constraint Guidelines","text":"<p>Use caret constraints (<code>^</code>) for most dependencies:</p> <pre><code># Allows 1.2.0 \u2264 version &lt; 2.0.0\nbasketball-stats = {path = \"../../libs/basketball-stats\", version = \"^1.2.0\"}\n\n# For pre-1.0 libraries, use tilde constraints to avoid breaking changes\nexperimental-lib = {path = \"../../libs/experimental-lib\", version = \"~0.3.0\"}\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#breaking-change-management","title":"Breaking Change Management","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#1-planning-breaking-changes","title":"1. Planning Breaking Changes","text":"<p>Before introducing breaking changes:</p> <ol> <li>Document the change: Update library README with migration guide</li> <li>Deprecation period: Mark old functionality as deprecated in a minor release</li> <li>Communication: Notify application maintainers of upcoming changes</li> </ol>"},{"location":"SHARED_LIBRARY_VERSIONING/#2-implementing-breaking-changes","title":"2. Implementing Breaking Changes","text":"<ol> <li>Create migration documentation in the library's README</li> <li>Bump major version using <code>poetry version major</code></li> <li>Update library changelog with clear migration instructions</li> <li>Update applications that consume the library</li> </ol>"},{"location":"SHARED_LIBRARY_VERSIONING/#3-migration-strategy","title":"3. Migration Strategy","text":"<p>For gradual migration:</p> <ol> <li>Version pinning: Pin applications to the last compatible version</li> <li>Parallel development: Applications can migrate at their own pace</li> <li>Testing: Verify compatibility before updating dependencies</li> </ol>"},{"location":"SHARED_LIBRARY_VERSIONING/#library-release-checklist","title":"Library Release Checklist","text":"<p>Before releasing a new library version:</p> <ul> <li>[ ] Update version in <code>pyproject.toml</code> using <code>poetry version</code></li> <li>[ ] Update <code>CHANGELOG.md</code> (if present) with changes</li> <li>[ ] Run tests: <code>poetry run pytest</code></li> <li>[ ] Run linting: <code>poetry run ruff check</code></li> <li>[ ] Update documentation if needed</li> <li>[ ] Commit version bump: <code>git commit -m \"bump: version X.Y.Z\"</code></li> <li>[ ] Tag release: <code>git tag vX.Y.Z</code> (optional, for tracking)</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#best-practices","title":"Best Practices","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#1-version-consistency","title":"1. Version Consistency","text":"<ul> <li>Use <code>poetry version</code> command to ensure consistent version bumping</li> <li>Keep versions in sync with actual changes (don't skip versions)</li> <li>Document breaking changes clearly in commit messages</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#2-dependency-updates","title":"2. Dependency Updates","text":"<ul> <li>Review library changes before updating dependencies in applications</li> <li>Test applications thoroughly after updating library dependencies</li> <li>Use version ranges (<code>^1.0.0</code>) rather than exact pins when possible</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#3-backward-compatibility","title":"3. Backward Compatibility","text":"<ul> <li>Maintain backward compatibility within major versions</li> <li>Use deprecation warnings before removing functionality</li> <li>Provide clear migration paths for breaking changes</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#4-development-workflow","title":"4. Development Workflow","text":"<ul> <li>Use local path dependencies during active development</li> <li>Consider version pinning for critical production applications</li> <li>Coordinate library updates across multiple consuming applications</li> </ul>"},{"location":"SHARED_LIBRARY_VERSIONING/#common-patterns","title":"Common Patterns","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#pattern-1-feature-development","title":"Pattern 1: Feature Development","text":"<pre><code># 1. Develop new feature in library\ncd libs/my-library\n# Work on feature...\npoetry run pytest  # Ensure tests pass\n\n# 2. Bump minor version for new feature\npoetry version minor  # 1.0.0 \u2192 1.1.0\n\n# 3. Update consuming applications (optional)\ncd apps/my-app\n# Update dependency version if needed\npoetry update my-library\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#pattern-2-bug-fix","title":"Pattern 2: Bug Fix","text":"<pre><code># 1. Fix bug in library\ncd libs/my-library\n# Fix the bug...\npoetry run pytest\n\n# 2. Bump patch version\npoetry version patch  # 1.1.0 \u2192 1.1.1\n\n# 3. Applications using ^1.1.0 will automatically get the fix\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#pattern-3-breaking-change","title":"Pattern 3: Breaking Change","text":"<pre><code># 1. Plan and communicate breaking change\n# 2. Implement change in library\ncd libs/my-library\n# Make breaking changes...\npoetry run pytest\n\n# 3. Bump major version\npoetry version major  # 1.1.1 \u2192 2.0.0\n\n# 4. Update applications one by one\ncd apps/my-app\n# Update code to work with new API\n# Update dependency version\npoetry add my-library@^2.0.0\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"SHARED_LIBRARY_VERSIONING/#issue-package-not-found-errors","title":"Issue: \"Package not found\" errors","text":"<p>Solution: Ensure the library path is correct and the library has a valid <code>pyproject.toml</code>:</p> <pre><code># Verify library structure\nls libs/my-library/pyproject.toml\nls libs/my-library/my_library/__init__.py\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#issue-version-conflicts-between-libraries","title":"Issue: Version conflicts between libraries","text":"<p>Solution: Use compatible version ranges and coordinate updates:</p> <pre><code># Check current versions\npoetry show | grep my-library\n\n# Update with compatible constraints\npoetry add my-library@^1.0.0\n</code></pre>"},{"location":"SHARED_LIBRARY_VERSIONING/#issue-development-changes-not-reflected","title":"Issue: Development changes not reflected","text":"<p>Solution: Ensure using development mode for local dependencies:</p> <pre><code>my-library = {path = \"../../libs/my-library\", develop = true}\n</code></pre> <p>This versioning strategy enables stable dependency management while maintaining the flexibility needed for monorepo development workflows.</p>"},{"location":"feature-request-automation/","title":"Feature Request Automation Documentation","text":"<p>This document provides guidance on using the AI-driven feature request creation system to automatically extract and create GitHub issues from planning documents.</p>"},{"location":"feature-request-automation/#overview","title":"Overview","text":"<p>The system consists of three main components:</p> <ol> <li>Analysis Document (<code>meta/plans/ai-driven-feature-request-creation.md</code>) - Comprehensive analysis of the approach and implementation strategy</li> <li>Feature Database (<code>meta/plans/extracted-feature-requests.json</code>) - Structured JSON containing all extracted feature requests</li> <li>Creation Script (<code>scripts/create-feature-issues.sh</code>) - Bash script using GitHub CLI to create issues</li> </ol>"},{"location":"feature-request-automation/#quick-start","title":"Quick Start","text":""},{"location":"feature-request-automation/#prerequisites","title":"Prerequisites","text":"<p>Before running the feature request creation script, ensure you have:</p> <ul> <li>GitHub CLI (gh) installed and authenticated</li> <li>jq installed for JSON processing</li> <li>Valid access to the GitHub repository</li> <li>Proper permissions to create issues</li> </ul>"},{"location":"feature-request-automation/#authentication-setup","title":"Authentication Setup","text":"<pre><code># Authenticate with GitHub CLI\ngh auth login\n\n# Verify authentication\ngh auth status\n</code></pre>"},{"location":"feature-request-automation/#running-the-script","title":"Running the Script","text":""},{"location":"feature-request-automation/#preview-issues-recommended-first-step","title":"Preview Issues (Recommended First Step)","text":"<pre><code># Preview all feature requests\n./scripts/create-feature-issues.sh --dry-run --verbose\n\n# Preview specific category\n./scripts/create-feature-issues.sh --dry-run --category frontend\n\n# Preview high-priority items only\n./scripts/create-feature-issues.sh --dry-run --priority high\n</code></pre>"},{"location":"feature-request-automation/#create-issues","title":"Create Issues","text":"<pre><code># Create all feature requests\n./scripts/create-feature-issues.sh\n\n# Create only frontend issues\n./scripts/create-feature-issues.sh --category frontend\n\n# Create only high-priority ETL pipeline issues\n./scripts/create-feature-issues.sh --category etl-pipeline --priority high\n</code></pre>"},{"location":"feature-request-automation/#available-categories","title":"Available Categories","text":"<p>The extracted feature requests are organized into the following categories:</p> <ul> <li><code>frontend</code> - UI/UX and client-side features</li> <li><code>etl-pipeline</code> - Data processing and transformation features</li> <li><code>mcp-server</code> - Model Context Protocol server features</li> <li><code>data-backfill</code> - Historical data backfill features</li> <li><code>aws-integration</code> - AWS infrastructure and integration features</li> </ul>"},{"location":"feature-request-automation/#available-priorities","title":"Available Priorities","text":"<p>Features are classified by priority:</p> <ul> <li><code>high</code> - Critical path features requiring immediate attention</li> <li><code>medium</code> - Important features for planned development</li> <li><code>low</code> - Future enhancements and optimizations</li> </ul>"},{"location":"feature-request-automation/#script-options","title":"Script Options","text":"Option Description Example <code>--dry-run</code> Preview issues without creating them <code>--dry-run</code> <code>--category CATEGORY</code> Filter by feature category <code>--category frontend</code> <code>--priority PRIORITY</code> Filter by priority level <code>--priority high</code> <code>--verbose</code> Enable detailed output <code>--verbose</code> <code>--help</code> Show usage information <code>--help</code>"},{"location":"feature-request-automation/#issue-format","title":"Issue Format","text":"<p>Created issues follow a standardized format:</p> <pre><code>## Description\n[Feature description from planning document]\n\n## Acceptance Criteria\n- [ ] Specific requirement 1\n- [ ] Specific requirement 2\n\n## Technical Requirements\n- Implementation detail 1\n- Implementation detail 2\n\n## Definition of Done\n- Success criteria 1\n- Success criteria 2\n\n## Source Information\n- **Epic:** [Epic name]\n- **Category:** [frontend/etl-pipeline/etc.]\n- **Priority:** [high/medium/low]\n- **Complexity:** [high/medium/low]\n- **Estimated Effort:** [time estimate]\n- **Source Document:** [original planning document]\n- **Source Section:** [specific section reference]\n\n## Metadata\n- **Feature ID:** [unique identifier]\n- **Generated from planning documents on:** [timestamp]\n</code></pre>"},{"location":"feature-request-automation/#labels-applied","title":"Labels Applied","text":"<p>Issues are automatically labeled based on their characteristics:</p> <ul> <li><code>feature</code> - All feature requests</li> <li><code>high-priority</code> - High-priority features</li> <li>Category-specific labels (<code>frontend</code>, <code>etl</code>, <code>mcp-server</code>, etc.)</li> <li>Feature-type labels (<code>setup</code>, <code>authentication</code>, <code>monitoring</code>, etc.)</li> </ul>"},{"location":"feature-request-automation/#error-handling","title":"Error Handling","text":"<p>The script includes comprehensive error handling:</p> <ul> <li>Duplicate Detection: Checks for existing issues with the same title</li> <li>Rate Limiting: Respects GitHub API limits with delays between requests</li> <li>Validation: Validates JSON format and GitHub authentication</li> <li>Logging: Creates detailed logs in <code>logs/issue-creation-[timestamp].log</code></li> </ul>"},{"location":"feature-request-automation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"feature-request-automation/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Authentication Errors <pre><code>gh auth login\ngh auth status\n</code></pre></p> </li> <li> <p>Permission Errors</p> </li> <li>Ensure you have write access to the repository</li> <li> <p>Check that your GitHub token has appropriate scopes</p> </li> <li> <p>JSON Parsing Errors <pre><code>jq empty meta/plans/extracted-feature-requests.json\n</code></pre></p> </li> <li> <p>Missing Dependencies <pre><code># Install GitHub CLI\n# See: https://cli.github.com/\n\n# Install jq\n# Ubuntu/Debian: apt-get install jq\n# macOS: brew install jq\n</code></pre></p> </li> </ol>"},{"location":"feature-request-automation/#log-analysis","title":"Log Analysis","text":"<p>Check the log file for detailed error information:</p> <pre><code>tail -f logs/issue-creation-[timestamp].log\n</code></pre>"},{"location":"feature-request-automation/#customization","title":"Customization","text":""},{"location":"feature-request-automation/#adding-new-features","title":"Adding New Features","text":"<p>To add new features to the system:</p> <ol> <li>Extract feature requests from new planning documents</li> <li>Add them to <code>extracted-feature-requests.json</code> following the established schema</li> <li>Update the <code>total_features</code> count in metadata</li> <li>Run the script to create the new issues</li> </ol>"},{"location":"feature-request-automation/#modifying-issue-format","title":"Modifying Issue Format","text":"<p>The issue format is controlled by the <code>format_issue_body()</code> function in the script. Modify this function to change how issues are formatted.</p>"},{"location":"feature-request-automation/#custom-labels","title":"Custom Labels","text":"<p>Labels are defined in the JSON file under <code>github_labels</code> for each feature. Modify these arrays to change the labels applied to issues.</p>"},{"location":"feature-request-automation/#best-practices","title":"Best Practices","text":"<ol> <li>Always use --dry-run first to preview what will be created</li> <li>Start with high-priority items to focus on critical features</li> <li>Process one category at a time for better organization</li> <li>Review created issues for quality and completeness</li> <li>Keep logs for audit trails and troubleshooting</li> </ol>"},{"location":"feature-request-automation/#maintenance","title":"Maintenance","text":""},{"location":"feature-request-automation/#updating-feature-requests","title":"Updating Feature Requests","text":"<p>When planning documents are updated:</p> <ol> <li>Re-run the extraction process (future automation)</li> <li>Update the JSON file with new or modified features</li> <li>Use the script to create only new issues (duplicate detection prevents re-creation)</li> </ol>"},{"location":"feature-request-automation/#monitoring-usage","title":"Monitoring Usage","text":"<p>Track the success of created issues:</p> <ul> <li>Monitor issue completion rates</li> <li>Gather feedback on issue quality</li> <li>Adjust extraction patterns based on developer feedback</li> </ul>"},{"location":"feature-request-automation/#integration-with-development-workflow","title":"Integration with Development Workflow","text":"<p>The generated issues are designed to integrate seamlessly with existing development workflows:</p> <ul> <li>Issues follow repository conventions</li> <li>Labels align with project categorization</li> <li>Acceptance criteria provide clear implementation guidance</li> <li>Source traceability maintains connection to planning documents</li> </ul>"},{"location":"feature-request-automation/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements to the system:</p> <ul> <li>Automated extraction from updated planning documents</li> <li>Integration with GitHub Projects for automatic project board management</li> <li>Batch operations for issue updates when plans change</li> <li>Integration with issue templates and automation</li> <li>Metrics and analytics on feature completion</li> </ul> <p>For questions or issues with the feature request automation system, refer to the comprehensive analysis in <code>meta/plans/ai-driven-feature-request-creation.md</code> or create an issue in the repository.</p>"},{"location":"libraries/","title":"Shared Libraries Overview","text":"<p>This section provides detailed documentation for all shared libraries in the Hoopstat Haus monorepo. Each library is designed to be reusable across multiple applications while following our development principles.</p>"},{"location":"libraries/#library-categories","title":"Library Categories","text":""},{"location":"libraries/#configuration-setup","title":"Configuration &amp; Setup","text":"<ul> <li>hoopstat-config: Standardized configuration management with type safety and validation</li> </ul>"},{"location":"libraries/#data-processing","title":"Data Processing","text":"<ul> <li>hoopstat-data: Core data processing utilities for basketball statistics</li> <li>ingestion: Data ingestion utilities for external data sources</li> </ul>"},{"location":"libraries/#testing-development","title":"Testing &amp; Development","text":"<ul> <li>hoopstat-e2e-testing: End-to-end testing framework and utilities</li> <li>hoopstat-mock-data: Mock data generation for testing scenarios</li> <li>example-math-utils: Example library demonstrating best practices</li> </ul>"},{"location":"libraries/#observability","title":"Observability","text":"<ul> <li>hoopstat-observability: Logging, monitoring, and observability utilities</li> </ul>"},{"location":"libraries/#usage-patterns","title":"Usage Patterns","text":"<p>All shared libraries follow consistent patterns:</p>"},{"location":"libraries/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>: <pre><code>[tool.poetry.dependencies]\nlibrary-name = {path = \"../libs/library-name\", develop = true}\n</code></pre></p>"},{"location":"libraries/#import-style","title":"Import Style","text":"<pre><code>from library_name import ClassName, function_name\n</code></pre>"},{"location":"libraries/#error-handling","title":"Error Handling","text":"<p>All libraries use consistent exception patterns and provide clear error messages.</p>"},{"location":"libraries/#documentation","title":"Documentation","text":"<p>Each library includes: - Comprehensive docstrings with Google-style formatting - Usage examples in docstrings - Type hints for all public APIs - Integration examples in documentation</p>"},{"location":"libraries/#best-practices","title":"Best Practices","text":"<p>When using shared libraries:</p> <ol> <li>Pin Versions: Use semantic versioning to pin library versions in production</li> <li>Follow Examples: Use the patterns shown in library documentation</li> <li>Handle Errors: Implement proper error handling for library exceptions</li> <li>Test Integration: Write tests for your usage of shared libraries</li> <li>Stay Updated: Monitor library changes and update dependencies regularly</li> </ol>"},{"location":"libraries/#development-guidelines","title":"Development Guidelines","text":"<p>When contributing to shared libraries:</p> <ol> <li>Maintain Backward Compatibility: Follow semantic versioning principles</li> <li>Write Tests: All public APIs must have comprehensive tests</li> <li>Document Everything: Include docstrings with examples for all public functions</li> <li>Follow Standards: Use consistent code style and patterns across libraries</li> <li>Consider Dependencies: Minimize external dependencies and document requirements</li> </ol>"},{"location":"libraries/example-math-utils/","title":"example-math-utils","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/example-math-utils/#description","title":"Description","text":"<p>example-math-utils</p> <p>Example math utilities library for demonstrating local development workflow</p>"},{"location":"libraries/example-math-utils/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nexample-math-utils = {path = \"../libs/example-math-utils\", develop = true}\n</code></pre>"},{"location":"libraries/example-math-utils/#usage","title":"Usage","text":"<pre><code>from example_math_utils import add, multiply, divide, subtract\n</code></pre>"},{"location":"libraries/example-math-utils/#api-reference","title":"API Reference","text":""},{"location":"libraries/example-math-utils/#functions","title":"Functions","text":""},{"location":"libraries/example-math-utils/#add","title":"add","text":"<pre><code>add(a: float, b: float) -&gt; float\n</code></pre> <p>Add two numbers together.</p> <p>This function demonstrates proper documentation and type hints for shared library functions.</p> <p>Args:     a: The first number to add     b: The second number to add</p> <p>Returns:     The sum of a and b</p> <p>Example:     &gt;&gt;&gt; add(2, 3)     5.0</p>"},{"location":"libraries/example-math-utils/#multiply","title":"multiply","text":"<pre><code>multiply(a: float, b: float) -&gt; float\n</code></pre> <p>Multiply two numbers together.</p> <p>Args:     a: The first number to multiply     b: The second number to multiply</p> <p>Returns:     The product of a and b</p> <p>Example:     &gt;&gt;&gt; multiply(4, 5)     20.0</p>"},{"location":"libraries/example-math-utils/#divide","title":"divide","text":"<pre><code>divide(a: float, b: float) -&gt; float\n</code></pre> <p>Divide the first number by the second number.</p> <p>Args:     a: The dividend     b: The divisor</p> <p>Returns:     The quotient of a divided by b</p> <p>Raises:     ValueError: If divisor is zero</p> <p>Example:     &gt;&gt;&gt; divide(10, 2)     5.0</p>"},{"location":"libraries/example-math-utils/#subtract","title":"subtract","text":"<pre><code>subtract(a: float, b: float) -&gt; float\n</code></pre> <p>Subtract the second number from the first number.</p> <p>This function was added to demonstrate hot reloading!</p> <p>Args:     a: The minuend (number to subtract from)     b: The subtrahend (number to subtract)</p> <p>Returns:     The difference of a minus b</p> <p>Example:     &gt;&gt;&gt; subtract(10, 3)     7.0</p>"},{"location":"libraries/example-math-utils/#examples","title":"Examples","text":""},{"location":"libraries/example-math-utils/#add_1","title":"add","text":"<pre><code>&gt;&gt;&gt; add(2, 3)\n</code></pre>"},{"location":"libraries/example-math-utils/#multiply_1","title":"multiply","text":"<pre><code>&gt;&gt;&gt; multiply(4, 5)\n</code></pre>"},{"location":"libraries/example-math-utils/#divide_1","title":"divide","text":"<pre><code>&gt;&gt;&gt; divide(10, 2)\n</code></pre>"},{"location":"libraries/example-math-utils/#subtract_1","title":"subtract","text":"<pre><code>&gt;&gt;&gt; subtract(10, 3)\n</code></pre>"},{"location":"libraries/hoopstat-config/","title":"hoopstat-config","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/hoopstat-config/#description","title":"Description","text":"<p>hoopstat-config</p> <p>Standardized configuration management library for Hoopstat Haus applications</p>"},{"location":"libraries/hoopstat-config/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nhoopstat-config = {path = \"../libs/hoopstat-config\", develop = true}\n</code></pre>"},{"location":"libraries/hoopstat-config/#usage","title":"Usage","text":"<pre><code>from hoopstat_config import ConfigManager, ConfigField, config_field, ConfigValidationError, ConfigFileError, load_config_file\n</code></pre>"},{"location":"libraries/hoopstat-config/#api-reference","title":"API Reference","text":""},{"location":"libraries/hoopstat-config/#classes","title":"Classes","text":""},{"location":"libraries/hoopstat-config/#configmanager","title":"ConfigManager","text":"<p>Base class for type-safe configuration management.</p> <p>This class provides a foundation for creating configuration classes that: - Load from multiple sources (defaults, files, environment variables) - Provide type safety and validation - Support multiple file formats - Give clear error messages - Track configuration sources for debugging</p> <p>Methods:</p> <ul> <li><code>load(cls: Any, config_file: Any, override_values: Any) -&gt; T</code></li> <li>Load configuration from multiple sources with precedence rules.</li> <li><code>load_from_file(cls: Any, config_file: str) -&gt; T</code></li> <li>Load configuration from a file only (no environment variables).</li> <li><code>get_field_sources(self) -&gt; Any</code></li> <li>Get information about where each field value came from.</li> <li><code>get_config_summary(self) -&gt; str</code></li> <li>Get a human-readable summary of the configuration.</li> <li><code>get_env_vars(self) -&gt; Any</code></li> <li>Get environment variable names for all fields that support them.</li> </ul>"},{"location":"libraries/hoopstat-config/#configvalidationerror","title":"ConfigValidationError","text":"<p>Raised when configuration validation fails.</p> <p>This exception provides detailed information about validation failures to help developers quickly identify and fix configuration issues.</p>"},{"location":"libraries/hoopstat-config/#configfileerror","title":"ConfigFileError","text":"<p>Raised when configuration file loading or parsing fails.</p> <p>This exception is used for file system errors, parsing errors, and other file-related issues during configuration loading.</p>"},{"location":"libraries/hoopstat-config/#configenvironmenterror","title":"ConfigEnvironmentError","text":"<p>Raised when environment variable processing fails.</p> <p>This exception is used when environment variables cannot be parsed or converted to the expected types.</p>"},{"location":"libraries/hoopstat-config/#configfield","title":"ConfigField","text":"<p>Defines a configuration field with support for environment variables and validation.</p> <p>This class provides a declarative way to define configuration fields with: - Default values - Environment variable mapping - Type conversion - Documentation - Validation</p> <p>Methods:</p> <ul> <li><code>get_env_value(self, field_type: Any) -&gt; Any</code></li> <li>Get and convert value from environment variable.</li> </ul>"},{"location":"libraries/hoopstat-config/#functions","title":"Functions","text":""},{"location":"libraries/hoopstat-config/#config_field","title":"config_field","text":"<pre><code>config_field(default: Any, env_var: Any, description: Any) -&gt; Any\n</code></pre> <p>Create a configuration field with environment variable support.</p> <p>This function creates a Pydantic field with additional metadata for environment variable handling.</p> <p>Args:     default: Default value for the field.     env_var: Environment variable name to read the value from.     description: Human-readable description of the field.     **kwargs: Additional arguments passed to pydantic.Field()</p> <p>Returns:     Pydantic Field for use in model definitions.</p>"},{"location":"libraries/hoopstat-config/#load","title":"load","text":"<pre><code>load(cls: Any, config_file: Any, override_values: Any) -&gt; T\n</code></pre> <p>Load configuration from multiple sources with precedence rules.</p> <p>Configuration sources (in order of precedence, later overrides earlier): 1. Class defaults 2. Configuration file (if provided) 3. Environment variables 4. Override values (if provided)</p> <p>Args:     config_file: Optional path to configuration file     override_values: Optional dictionary of values to override</p> <p>Returns:     Configured instance of the class</p> <p>Raises:     ConfigValidationError: If configuration validation fails     ConfigFileError: If configuration file cannot be loaded</p>"},{"location":"libraries/hoopstat-config/#load_from_file","title":"load_from_file","text":"<pre><code>load_from_file(cls: Any, config_file: str) -&gt; T\n</code></pre> <p>Load configuration from a file only (no environment variables).</p> <p>Args:     config_file: Path to configuration file</p> <p>Returns:     Configured instance of the class</p> <p>Raises:     ConfigValidationError: If configuration validation fails     ConfigFileError: If configuration file cannot be loaded</p>"},{"location":"libraries/hoopstat-config/#get_field_sources","title":"get_field_sources","text":"<pre><code>get_field_sources(self) -&gt; Any\n</code></pre> <p>Get information about where each field value came from.</p> <p>Returns:     Dictionary mapping field names to source types:     - 'default': From class default value     - 'file': From configuration file     - 'environment': From environment variable     - 'override': From override values</p>"},{"location":"libraries/hoopstat-config/#get_config_summary","title":"get_config_summary","text":"<pre><code>get_config_summary(self) -&gt; str\n</code></pre> <p>Get a human-readable summary of the configuration.</p> <p>Returns:     Formatted string showing all configuration values and their sources</p>"},{"location":"libraries/hoopstat-config/#get_env_vars","title":"get_env_vars","text":"<pre><code>get_env_vars(self) -&gt; Any\n</code></pre> <p>Get environment variable names for all fields that support them.</p> <p>Returns:     Dictionary mapping field names to environment variable names</p>"},{"location":"libraries/hoopstat-config/#config_field_1","title":"config_field","text":"<pre><code>config_field(default: Any, env_var: Any, description: Any) -&gt; Any\n</code></pre> <p>Create a configuration field with environment variable support.</p> <p>This is a convenience function that creates a ConfigField and returns its Pydantic field for use in class definitions.</p> <p>Args:     default: Default value for the field.     env_var: Environment variable name to read the value from.     description: Human-readable description of the field.     **kwargs: Additional arguments passed to pydantic.Field()</p> <p>Returns:     Pydantic Field object for use in model definitions.</p>"},{"location":"libraries/hoopstat-config/#get_env_value","title":"get_env_value","text":"<pre><code>get_env_value(self, field_type: Any) -&gt; Any\n</code></pre> <p>Get and convert value from environment variable.</p> <p>Args:     field_type: The expected type for the field value.</p> <p>Returns:     Converted value from environment variable, or None if not set.</p> <p>Raises:     ConfigEnvironmentError: If environment variable exists but cannot be         converted.</p>"},{"location":"libraries/hoopstat-config/#load_config_file","title":"load_config_file","text":"<pre><code>load_config_file(file_path: str) -&gt; Any\n</code></pre> <p>Load configuration from a file, auto-detecting format from extension.</p> <p>Supported formats: - JSON (.json) - YAML (.yaml, .yml) - requires PyYAML - TOML (.toml) - requires tomli (Python &lt; 3.11) or uses stdlib tomllib   (Python &gt;= 3.11)</p> <p>Args:     file_path: Path to the configuration file.</p> <p>Returns:     Dictionary containing the parsed configuration.</p> <p>Raises:     ConfigFileError: If the file cannot be read or parsed.</p>"},{"location":"libraries/hoopstat-config/#get_supported_formats","title":"get_supported_formats","text":"<pre><code>get_supported_formats() -&gt; Any\n</code></pre> <p>Get information about supported configuration file formats.</p> <p>Returns:     Dictionary mapping format names to availability status.</p>"},{"location":"libraries/hoopstat-data/","title":"hoopstat-data","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/hoopstat-data/#description","title":"Description","text":"<p>Hoopstat Data Processing Utilities</p> <p>A shared library for basketball statistics data processing, validation, transformation, quality checking, and Gold layer partitioning.</p>"},{"location":"libraries/hoopstat-data/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nhoopstat-data = {path = \"../libs/hoopstat-data\", develop = true}\n</code></pre>"},{"location":"libraries/hoopstat-data/#usage","title":"Usage","text":"<pre><code>from hoopstat_data import PlayerStats, TeamStats, GameStats, GoldPlayerDailyStats, GoldPlayerSeasonSummary, GoldTeamDailyStats, validate_player_stats, validate_team_stats, validate_game_stats, validate_stat_ranges, normalize_team_name, calculate_efficiency_rating, standardize_position, clean_and_transform_record, clean_batch, validate_and_standardize_season, check_data_completeness, detect_outliers, DataCleaningRulesEngine, TransformationResult, S3PartitionKey, PartitionType, FileSizeOptimizer, QueryPatternOptimizer, PartitionHealthChecker, create_player_daily_partition, create_player_season_partition, create_team_daily_partition\n</code></pre>"},{"location":"libraries/hoopstat-data/#api-reference","title":"API Reference","text":""},{"location":"libraries/hoopstat-data/#classes","title":"Classes","text":""},{"location":"libraries/hoopstat-data/#transformationresult","title":"TransformationResult","text":"<p>Result of a data transformation operation.</p>"},{"location":"libraries/hoopstat-data/#datacleaningrulesengine","title":"DataCleaningRulesEngine","text":"<p>Configurable rules engine for data cleaning and standardization.</p> <p>Applies data cleaning, standardization, and conforming transformations to NBA data based on configurable YAML rules.</p> <p>Methods:</p> <ul> <li><code>standardize_team_name(self, team_name: str, use_fuzzy_matching: bool) -&gt; TransformationResult</code></li> <li>Standardize team name using mapping table and fuzzy matching.</li> <li><code>standardize_position(self, position: str) -&gt; TransformationResult</code></li> <li>Standardize player position using mapping table.</li> <li><code>handle_null_values(self, data: Any, entity_type: str) -&gt; Any</code></li> <li>Handle null values according to configured rules.</li> <li><code>clean_numeric_field(self, value: Any, field_name: str) -&gt; TransformationResult</code></li> <li>Clean and validate numeric field with business rules.</li> <li><code>standardize_datetime(self, value: Any, field_name: str) -&gt; TransformationResult</code></li> <li>Standardize date/time values to consistent format.</li> <li><code>apply_fuzzy_matching(self, value: str, candidates: Any, field_name: str) -&gt; TransformationResult</code></li> <li>Apply fuzzy string matching to find best candidate.</li> <li><code>process_batch(self, records: Any, entity_type: str) -&gt; Any</code></li> <li>Process a batch of records with all cleaning rules.</li> <li><code>get_transformation_summary(self) -&gt; Any</code></li> <li>Get summary of all transformations applied.</li> <li><code>clear_transformation_log(self) -&gt; None</code></li> <li>Clear the transformation log.</li> </ul>"},{"location":"libraries/hoopstat-data/#partitiontype","title":"PartitionType","text":"<p>Supported partition types for Gold layer data.</p>"},{"location":"libraries/hoopstat-data/#s3partitionkey","title":"S3PartitionKey","text":"<p>S3 partition key for Gold layer data with hierarchical structure.</p> <p>Methods:</p> <ul> <li><code>validate_season_format(cls, v: str) -&gt; str</code></li> <li>Validate NBA season format.</li> <li><code>validate_date_format(cls, v: Any) -&gt; Any</code></li> <li>Validate date format if provided.</li> <li><code>s3_prefix(self) -&gt; str</code></li> <li>Generate S3 prefix from partition key components.</li> <li><code>s3_path(self) -&gt; str</code></li> <li>Generate full S3 path including bucket and filename.</li> <li><code>local_path(self) -&gt; Path</code></li> <li>Generate local file path structure matching S3 hierarchy.</li> </ul>"},{"location":"libraries/hoopstat-data/#filesizeoptimizer","title":"FileSizeOptimizer","text":"<p>Utilities for optimizing file sizes for Lambda performance.</p> <p>Methods:</p> <ul> <li><code>estimate_parquet_size(row_count: int, avg_row_size_bytes: int) -&gt; int</code></li> <li>Estimate Parquet file size based on row count.</li> <li><code>should_split_file(cls, row_count: int, avg_row_size_bytes: int) -&gt; bool</code></li> <li>Determine if file should be split based on estimated size.</li> <li><code>recommend_split_strategy(cls, row_count: int, avg_row_size_bytes: int) -&gt; Any</code></li> <li>Recommend splitting strategy for large files.</li> </ul>"},{"location":"libraries/hoopstat-data/#querypatternoptimizer","title":"QueryPatternOptimizer","text":"<p>Utilities for optimizing data layout for common query patterns.</p> <p>Methods:</p> <ul> <li><code>get_optimal_partition_key(cls, query_pattern: str) -&gt; S3PartitionKey</code></li> <li>Generate optimal partition key for a given query pattern.</li> <li><code>list_query_patterns(cls) -&gt; Any</code></li> <li>List available query patterns with descriptions.</li> </ul>"},{"location":"libraries/hoopstat-data/#partitionhealthchecker","title":"PartitionHealthChecker","text":"<p>Utilities for monitoring partition health and performance.</p> <p>Methods:</p> <ul> <li><code>calculate_partition_hash(partition_key: S3PartitionKey) -&gt; str</code></li> <li>Calculate a hash for partition identification and change detection.</li> <li><code>validate_partition_structure(partition_key: S3PartitionKey) -&gt; Any</code></li> <li>Validate partition structure against ADR-020 standards.</li> </ul>"},{"location":"libraries/hoopstat-data/#validationmode","title":"ValidationMode","text":"<p>Validation strictness levels for schema validation.</p>"},{"location":"libraries/hoopstat-data/#datalineage","title":"DataLineage","text":"<p>Data lineage tracking information.</p>"},{"location":"libraries/hoopstat-data/#basesilvermodel","title":"BaseSilverModel","text":"<p>Base model for all Silver layer entities with common metadata.</p>"},{"location":"libraries/hoopstat-data/#playerstats","title":"PlayerStats","text":"<p>Player statistics data model.</p> <p>Methods:</p> <ul> <li><code>validate_field_goals(cls, v, info) -&gt; Any</code></li> <li>Ensure field goals attempted &gt;= field goals made.</li> <li><code>validate_points_range(cls, v, info) -&gt; Any</code></li> <li>Validate points are within reasonable NBA game ranges.</li> <li><code>validate_player_name(cls, v) -&gt; Any</code></li> <li>Ensure player name is properly formatted.</li> <li><code>validate_shooting_consistency(self) -&gt; Any</code></li> <li>Validate shooting statistics consistency.</li> </ul>"},{"location":"libraries/hoopstat-data/#teamstats","title":"TeamStats","text":"<p>Team statistics data model.</p> <p>Methods:</p> <ul> <li><code>validate_team_name(cls, v) -&gt; Any</code></li> <li>Ensure team name is valid NBA team.</li> <li><code>validate_points_range(cls, v, info) -&gt; Any</code></li> <li>Validate team points are within reasonable NBA game ranges.</li> <li><code>validate_team_shooting_stats(self) -&gt; Any</code></li> <li>Validate team shooting statistics consistency.</li> </ul>"},{"location":"libraries/hoopstat-data/#gamestats","title":"GameStats","text":"<p>Game statistics data model.</p> <p>Methods:</p> <ul> <li><code>validate_game_date(cls, v) -&gt; Any</code></li> <li>Ensure game date is in ISO format if provided.</li> <li><code>validate_season_format(cls, v) -&gt; Any</code></li> <li>Validate NBA season format (e.g., '2023-24').</li> <li><code>validate_game_logic(self) -&gt; Any</code></li> <li>Validate game logic and constraints.</li> </ul>"},{"location":"libraries/hoopstat-data/#basegoldmodel","title":"BaseGoldModel","text":"<p>Base model for all Gold layer entities with computed metrics.</p>"},{"location":"libraries/hoopstat-data/#goldplayerdailystats","title":"GoldPlayerDailyStats","text":"<p>Gold layer player daily statistics with pre-computed metrics.</p> <p>Methods:</p> <ul> <li><code>validate_ts_percentage(cls, v) -&gt; Any</code></li> <li>Validate true shooting percentage is reasonable.</li> <li><code>validate_season_format(cls, v) -&gt; Any</code></li> <li>Validate NBA season format.</li> </ul>"},{"location":"libraries/hoopstat-data/#goldplayerseasonsummary","title":"GoldPlayerSeasonSummary","text":"<p>Gold layer player season summary with aggregated statistics.</p> <p>Methods:</p> <ul> <li><code>validate_season_format(cls, v) -&gt; Any</code></li> <li>Validate NBA season format.</li> </ul>"},{"location":"libraries/hoopstat-data/#goldteamdailystats","title":"GoldTeamDailyStats","text":"<p>Gold layer team daily statistics with computed metrics.</p>"},{"location":"libraries/hoopstat-data/#schemaevolution","title":"SchemaEvolution","text":"<p>Handles schema versioning and evolution.</p> <p>Methods:</p> <ul> <li><code>migrate_from_version(data: Any, from_version: str, to_version: str) -&gt; Any</code></li> <li>Migrate data from one schema version to another.</li> </ul>"},{"location":"libraries/hoopstat-data/#functions","title":"Functions","text":""},{"location":"libraries/hoopstat-data/#normalize_team_name","title":"normalize_team_name","text":"<pre><code>normalize_team_name(team_name: str, use_rules_engine: bool) -&gt; str\n</code></pre> <p>Normalize team names to a standard format.</p> <p>Args:     team_name: Raw team name     use_rules_engine: Whether to use the configurable rules engine</p> <p>Returns:     Normalized team name</p> <p>Example:     &gt;&gt;&gt; normalize_team_name(\"lakers\")     \"Los Angeles Lakers\"     &gt;&gt;&gt; normalize_team_name(\"LA Lakers\")     \"Los Angeles Lakers\"</p>"},{"location":"libraries/hoopstat-data/#calculate_efficiency_rating","title":"calculate_efficiency_rating","text":"<pre><code>calculate_efficiency_rating(stats: Any) -&gt; float\n</code></pre> <p>Calculate player efficiency rating (PER-like metric).</p> <p>Simplified calculation: (Points + Rebounds + Assists + Steals + Blocks - Turnovers) / Minutes</p> <p>Args:     stats: Dictionary containing player statistics</p> <p>Returns:     Efficiency rating as a float</p> <p>Example:     &gt;&gt;&gt; stats = {     ...     \"points\": 25, \"rebounds\": 10, \"assists\": 5,     ...     \"steals\": 2, \"blocks\": 1, \"turnovers\": 3, \"minutes_played\": 35     ... }     &gt;&gt;&gt; calculate_efficiency_rating(stats)     1.14</p>"},{"location":"libraries/hoopstat-data/#standardize_position","title":"standardize_position","text":"<pre><code>standardize_position(position: str, use_rules_engine: bool) -&gt; str\n</code></pre> <p>Standardize player position to common abbreviations.</p> <p>Args:     position: Raw position string     use_rules_engine: Whether to use the configurable rules engine</p> <p>Returns:     Standardized position abbreviation</p> <p>Example:     &gt;&gt;&gt; standardize_position(\"Point Guard\")     \"PG\"     &gt;&gt;&gt; standardize_position(\"center\")     \"C\"</p>"},{"location":"libraries/hoopstat-data/#calculate_shooting_percentage","title":"calculate_shooting_percentage","text":"<pre><code>calculate_shooting_percentage(made: int, attempted: int) -&gt; Any\n</code></pre> <p>Calculate shooting percentage with proper handling of edge cases.</p> <p>Args:     made: Number of shots made     attempted: Number of shots attempted</p> <p>Returns:     Shooting percentage as decimal (0.0 to 1.0), or None if invalid</p> <p>Example:     &gt;&gt;&gt; calculate_shooting_percentage(8, 15)     0.533     &gt;&gt;&gt; calculate_shooting_percentage(0, 0)     None</p>"},{"location":"libraries/hoopstat-data/#convert_minutes_to_decimal","title":"convert_minutes_to_decimal","text":"<pre><code>convert_minutes_to_decimal(minutes_str: str) -&gt; Any\n</code></pre> <p>Convert minutes from \"MM:SS\" format to decimal minutes.</p> <p>Args:     minutes_str: Time string in \"MM:SS\" format</p> <p>Returns:     Decimal minutes, or None if invalid format</p> <p>Example:     &gt;&gt;&gt; convert_minutes_to_decimal(\"35:30\")     35.5     &gt;&gt;&gt; convert_minutes_to_decimal(\"12:45\")     12.75</p>"},{"location":"libraries/hoopstat-data/#normalize_stat_per_game","title":"normalize_stat_per_game","text":"<pre><code>normalize_stat_per_game(stat_value: float, games_played: int) -&gt; Any\n</code></pre> <p>Normalize a cumulative stat to per-game average.</p> <p>Args:     stat_value: Cumulative statistic value     games_played: Number of games played</p> <p>Returns:     Per-game average, or None if invalid</p> <p>Example:     &gt;&gt;&gt; normalize_stat_per_game(250, 10)     25.0</p>"},{"location":"libraries/hoopstat-data/#clean_and_transform_record","title":"clean_and_transform_record","text":"<pre><code>clean_and_transform_record(record: Any, entity_type: str, use_rules_engine: bool) -&gt; Any\n</code></pre> <p>Apply comprehensive cleaning and transformation to a single record.</p> <p>Args:     record: Dictionary containing raw data     entity_type: Type of entity (player_stats, team_stats, game_stats)     use_rules_engine: Whether to use the configurable rules engine</p> <p>Returns:     Cleaned and transformed record</p> <p>Example:     &gt;&gt;&gt; record = {\"team_name\": \"lakers\", \"points\": \"25\", \"position\": \"point guard\"}     &gt;&gt;&gt; clean_and_transform_record(record)     {\"team_name\": \"Los Angeles Lakers\", \"points\": 25, \"position\": \"PG\"}</p>"},{"location":"libraries/hoopstat-data/#clean_batch","title":"clean_batch","text":"<pre><code>clean_batch(records: Any, entity_type: str, batch_size: int) -&gt; Any\n</code></pre> <p>Clean a batch of records efficiently.</p> <p>Args:     records: List of records to clean     entity_type: Type of entity (player_stats, team_stats, game_stats)     batch_size: Number of records to process in each batch</p> <p>Returns:     List of cleaned records</p> <p>Example:     &gt;&gt;&gt; records = [{\"team_name\": \"lakers\"}, {\"team_name\": \"warriors\"}]     &gt;&gt;&gt; clean_batch(records)     [{\"team_name\": \"Los Angeles Lakers\"}, {\"team_name\": \"Golden State Warriors\"}]</p>"},{"location":"libraries/hoopstat-data/#validate_and_standardize_season","title":"validate_and_standardize_season","text":"<pre><code>validate_and_standardize_season(season_str: str) -&gt; Any\n</code></pre> <p>Validate and standardize NBA season format.</p> <p>Args:     season_str: Raw season string</p> <p>Returns:     Standardized season string (e.g., \"2023-24\") or None if invalid</p> <p>Example:     &gt;&gt;&gt; validate_and_standardize_season(\"2023-2024\")     \"2023-24\"     &gt;&gt;&gt; validate_and_standardize_season(\"23-24\")     \"2023-24\"</p>"},{"location":"libraries/hoopstat-data/#check_data_completeness","title":"check_data_completeness","text":"<pre><code>check_data_completeness(data: Any, required_fields: Any) -&gt; Any\n</code></pre> <p>Check data completeness and return completion metrics.</p> <p>Args:     data: Dictionary containing data to check     required_fields: Optional list of required field names</p> <p>Returns:     Dictionary with completeness metrics</p> <p>Example:     &gt;&gt;&gt; data = {\"points\": 25, \"rebounds\": None, \"assists\": 5}     &gt;&gt;&gt; result = check_data_completeness(data)  # doctest: +SKIP     # Returns completeness metrics dict</p>"},{"location":"libraries/hoopstat-data/#detect_outliers","title":"detect_outliers","text":"<pre><code>detect_outliers(values: Any, method: str, threshold: float) -&gt; Any\n</code></pre> <p>Detect outliers in a list of numerical values.</p> <p>Args:     values: List of numerical values     method: Detection method (\"iqr\" or \"zscore\")     threshold: Threshold for outlier detection</p> <p>Returns:     List of indices of detected outliers</p> <p>Example:     &gt;&gt;&gt; values = [10, 12, 11, 13, 15, 50, 14]     &gt;&gt;&gt; detect_outliers(values)     [5]  # Index of the value 50</p>"},{"location":"libraries/hoopstat-data/#validate_stat_consistency","title":"validate_stat_consistency","text":"<pre><code>validate_stat_consistency(player_stats: Any) -&gt; Any\n</code></pre> <p>Validate consistency across multiple player stat records.</p> <p>Args:     player_stats: List of player statistics dictionaries</p> <p>Returns:     List of consistency issues found</p> <p>Example:     &gt;&gt;&gt; stats = [     ...     {\"player_id\": \"123\", \"points\": 25, \"field_goals_made\": 10},     ...     {\"player_id\": \"123\", \"points\": -5, \"field_goals_made\": 15}     ... ]     &gt;&gt;&gt; issues = validate_stat_consistency(stats)  # doctest: +SKIP     # Returns list of consistency issues</p>"},{"location":"libraries/hoopstat-data/#calculate_data_quality_score","title":"calculate_data_quality_score","text":"<pre><code>calculate_data_quality_score(data: Any, weights: Any) -&gt; float\n</code></pre> <p>Calculate an overall data quality score (0.0 to 1.0).</p> <p>Args:     data: Dictionary containing data to assess     weights: Optional weights for different quality factors</p> <p>Returns:     Quality score from 0.0 (poor) to 1.0 (excellent)</p> <p>Example:     &gt;&gt;&gt; data = {\"points\": 25, \"rebounds\": 10, \"assists\": 5}     &gt;&gt;&gt; calculate_data_quality_score(data)     0.85</p>"},{"location":"libraries/hoopstat-data/#identify_missing_critical_stats","title":"identify_missing_critical_stats","text":"<pre><code>identify_missing_critical_stats(data: Any) -&gt; Any\n</code></pre> <p>Identify missing statistics that are critical for analysis.</p> <p>Args:     data: Dictionary containing player/team statistics</p> <p>Returns:     List of missing critical statistics</p> <p>Example:     &gt;&gt;&gt; data = {\"rebounds\": 10, \"assists\": 5}     &gt;&gt;&gt; identify_missing_critical_stats(data)     ['points']</p>"},{"location":"libraries/hoopstat-data/#compare_stat_distributions","title":"compare_stat_distributions","text":"<pre><code>compare_stat_distributions(dataset1: Any, dataset2: Any, stat_name: str) -&gt; Any\n</code></pre> <p>Compare statistical distributions between two datasets.</p> <p>Args:     dataset1: First dataset     dataset2: Second dataset     stat_name: Name of the statistic to compare</p> <p>Returns:     Dictionary with comparison metrics</p> <p>Example:     &gt;&gt;&gt; data1 = [{\"points\": 20}, {\"points\": 25}]     &gt;&gt;&gt; data2 = [{\"points\": 15}, {\"points\": 30}]     &gt;&gt;&gt; compare_stat_distributions(data1, data2, \"points\")     {'mean_diff': 0.0, 'std_diff': 3.54, 'sample_sizes': [2, 2]}</p>"},{"location":"libraries/hoopstat-data/#extract_values","title":"extract_values","text":"<pre><code>extract_values(dataset, stat) -&gt; Any\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_player_stats","title":"validate_player_stats","text":"<pre><code>validate_player_stats(stats_data: Any) -&gt; bool\n</code></pre> <p>Validate player statistics data for consistency and logical constraints.</p> <p>Args:     stats_data: Dictionary containing player statistics</p> <p>Returns:     bool: True if all validations pass, False otherwise</p> <p>Example:     &gt;&gt;&gt; stats = {\"points\": 25, \"rebounds\": 10, \"assists\": 5}     &gt;&gt;&gt; validate_player_stats(stats)     True</p>"},{"location":"libraries/hoopstat-data/#validate_team_stats","title":"validate_team_stats","text":"<pre><code>validate_team_stats(stats_data: Any) -&gt; bool\n</code></pre> <p>Validate team statistics data for consistency and logical constraints.</p> <p>Args:     stats_data: Dictionary containing team statistics</p> <p>Returns:     bool: True if all validations pass, False otherwise</p> <p>Example:     &gt;&gt;&gt; stats = {\"team_name\": \"Lakers\", \"points\": 120, \"field_goals_made\": 45}     &gt;&gt;&gt; validate_team_stats(stats)     True</p>"},{"location":"libraries/hoopstat-data/#validate_game_stats","title":"validate_game_stats","text":"<pre><code>validate_game_stats(stats_data: Any) -&gt; bool\n</code></pre> <p>Validate game statistics data for consistency and logical constraints.</p> <p>Args:     stats_data: Dictionary containing game statistics</p> <p>Returns:     bool: True if all validations pass, False otherwise</p> <p>Example:     &gt;&gt;&gt; stats = {\"home_score\": 110, \"away_score\": 105, \"game_id\": \"game_123\"}     &gt;&gt;&gt; validate_game_stats(stats)     True</p>"},{"location":"libraries/hoopstat-data/#validate_stat_ranges","title":"validate_stat_ranges","text":"<pre><code>validate_stat_ranges(stats_data: Any, stat_ranges: Any) -&gt; Any\n</code></pre> <p>Validate that statistics fall within expected ranges.</p> <p>Args:     stats_data: Dictionary containing statistics to validate     stat_ranges: Optional dictionary of (min, max) ranges for each stat</p> <p>Returns:     List of validation error messages (empty if all valid)</p> <p>Example:     &gt;&gt;&gt; stats = {\"points\": 25, \"rebounds\": -5}     &gt;&gt;&gt; validate_stat_ranges(stats)     ['rebounds value -5 is outside expected range (0, 50)']</p>"},{"location":"libraries/hoopstat-data/#standardize_team_name","title":"standardize_team_name","text":"<pre><code>standardize_team_name(self, team_name: str, use_fuzzy_matching: bool) -&gt; TransformationResult\n</code></pre> <p>Standardize team name using mapping table and fuzzy matching.</p> <p>Args:     team_name: Raw team name     use_fuzzy_matching: Whether to use fuzzy matching as fallback</p> <p>Returns:     TransformationResult with standardized team name</p>"},{"location":"libraries/hoopstat-data/#standardize_position_1","title":"standardize_position","text":"<pre><code>standardize_position(self, position: str) -&gt; TransformationResult\n</code></pre> <p>Standardize player position using mapping table.</p> <p>Args:     position: Raw position string</p> <p>Returns:     TransformationResult with standardized position</p>"},{"location":"libraries/hoopstat-data/#handle_null_values","title":"handle_null_values","text":"<pre><code>handle_null_values(self, data: Any, entity_type: str) -&gt; Any\n</code></pre> <p>Handle null values according to configured rules.</p> <p>Args:     data: Dictionary containing data to clean     entity_type: Type of entity (player_stats, team_stats, game_stats)</p> <p>Returns:     Cleaned data dictionary</p>"},{"location":"libraries/hoopstat-data/#clean_numeric_field","title":"clean_numeric_field","text":"<pre><code>clean_numeric_field(self, value: Any, field_name: str) -&gt; TransformationResult\n</code></pre> <p>Clean and validate numeric field with business rules.</p> <p>Args:     value: Raw numeric value     field_name: Name of the field for validation rules</p> <p>Returns:     TransformationResult with cleaned numeric value</p>"},{"location":"libraries/hoopstat-data/#standardize_datetime","title":"standardize_datetime","text":"<pre><code>standardize_datetime(self, value: Any, field_name: str) -&gt; TransformationResult\n</code></pre> <p>Standardize date/time values to consistent format.</p> <p>Args:     value: Raw datetime value     field_name: Name of the field (for specific handling)</p> <p>Returns:     TransformationResult with standardized datetime</p>"},{"location":"libraries/hoopstat-data/#apply_fuzzy_matching","title":"apply_fuzzy_matching","text":"<pre><code>apply_fuzzy_matching(self, value: str, candidates: Any, field_name: str) -&gt; TransformationResult\n</code></pre> <p>Apply fuzzy string matching to find best candidate.</p> <p>Args:     value: String value to match     candidates: List of candidate values to match against     field_name: Field name for configuration lookup</p> <p>Returns:     TransformationResult with best match or original value</p>"},{"location":"libraries/hoopstat-data/#process_batch","title":"process_batch","text":"<pre><code>process_batch(self, records: Any, entity_type: str) -&gt; Any\n</code></pre> <p>Process a batch of records with all cleaning rules.</p> <p>Args:     records: List of record dictionaries to process     entity_type: Type of entity (player_stats, team_stats, game_stats)</p> <p>Returns:     Tuple of (cleaned_records, transformation_results)</p>"},{"location":"libraries/hoopstat-data/#get_transformation_summary","title":"get_transformation_summary","text":"<pre><code>get_transformation_summary(self) -&gt; Any\n</code></pre> <p>Get summary of all transformations applied.</p> <p>Returns:     Dictionary with transformation statistics</p>"},{"location":"libraries/hoopstat-data/#clear_transformation_log","title":"clear_transformation_log","text":"<pre><code>clear_transformation_log(self) -&gt; None\n</code></pre> <p>Clear the transformation log.</p>"},{"location":"libraries/hoopstat-data/#create_player_daily_partition","title":"create_player_daily_partition","text":"<pre><code>create_player_daily_partition(season: str, player_id: str, date: str, bucket: str, filename: str) -&gt; S3PartitionKey\n</code></pre> <p>Create partition key for player daily stats.</p>"},{"location":"libraries/hoopstat-data/#create_player_season_partition","title":"create_player_season_partition","text":"<pre><code>create_player_season_partition(season: str, player_id: str, bucket: str, filename: str) -&gt; S3PartitionKey\n</code></pre> <p>Create partition key for player season summary.</p>"},{"location":"libraries/hoopstat-data/#create_team_daily_partition","title":"create_team_daily_partition","text":"<pre><code>create_team_daily_partition(season: str, team_id: str, date: str, bucket: str, filename: str) -&gt; S3PartitionKey\n</code></pre> <p>Create partition key for team daily stats.</p>"},{"location":"libraries/hoopstat-data/#validate_season_format","title":"validate_season_format","text":"<pre><code>validate_season_format(cls, v: str) -&gt; str\n</code></pre> <p>Validate NBA season format.</p>"},{"location":"libraries/hoopstat-data/#validate_date_format","title":"validate_date_format","text":"<pre><code>validate_date_format(cls, v: Any) -&gt; Any\n</code></pre> <p>Validate date format if provided.</p>"},{"location":"libraries/hoopstat-data/#s3_prefix","title":"s3_prefix","text":"<pre><code>s3_prefix(self) -&gt; str\n</code></pre> <p>Generate S3 prefix from partition key components.</p>"},{"location":"libraries/hoopstat-data/#s3_path","title":"s3_path","text":"<pre><code>s3_path(self) -&gt; str\n</code></pre> <p>Generate full S3 path including bucket and filename.</p>"},{"location":"libraries/hoopstat-data/#local_path","title":"local_path","text":"<pre><code>local_path(self) -&gt; Path\n</code></pre> <p>Generate local file path structure matching S3 hierarchy.</p>"},{"location":"libraries/hoopstat-data/#estimate_parquet_size","title":"estimate_parquet_size","text":"<pre><code>estimate_parquet_size(row_count: int, avg_row_size_bytes: int) -&gt; int\n</code></pre> <p>Estimate Parquet file size based on row count.</p> <p>Args:     row_count: Number of rows in the dataset     avg_row_size_bytes: Average size per row in bytes</p> <p>Returns:     Estimated file size in bytes</p>"},{"location":"libraries/hoopstat-data/#should_split_file","title":"should_split_file","text":"<pre><code>should_split_file(cls, row_count: int, avg_row_size_bytes: int) -&gt; bool\n</code></pre> <p>Determine if file should be split based on estimated size.</p> <p>Args:     row_count: Number of rows in the dataset     avg_row_size_bytes: Average size per row in bytes</p> <p>Returns:     True if file should be split</p>"},{"location":"libraries/hoopstat-data/#recommend_split_strategy","title":"recommend_split_strategy","text":"<pre><code>recommend_split_strategy(cls, row_count: int, avg_row_size_bytes: int) -&gt; Any\n</code></pre> <p>Recommend splitting strategy for large files.</p> <p>Args:     row_count: Number of rows in the dataset     avg_row_size_bytes: Average size per row in bytes</p> <p>Returns:     Dictionary with splitting recommendations</p>"},{"location":"libraries/hoopstat-data/#get_optimal_partition_key","title":"get_optimal_partition_key","text":"<pre><code>get_optimal_partition_key(cls, query_pattern: str) -&gt; S3PartitionKey\n</code></pre> <p>Generate optimal partition key for a given query pattern.</p> <p>Args:     query_pattern: Name of the query pattern     **kwargs: Parameters for partition key generation</p> <p>Returns:     Optimized S3PartitionKey</p> <p>Raises:     ValueError: If query pattern is unknown or required parameters missing</p>"},{"location":"libraries/hoopstat-data/#list_query_patterns","title":"list_query_patterns","text":"<pre><code>list_query_patterns(cls) -&gt; Any\n</code></pre> <p>List available query patterns with descriptions.</p> <p>Returns:     Dictionary mapping pattern names to descriptions</p>"},{"location":"libraries/hoopstat-data/#calculate_partition_hash","title":"calculate_partition_hash","text":"<pre><code>calculate_partition_hash(partition_key: S3PartitionKey) -&gt; str\n</code></pre> <p>Calculate a hash for partition identification and change detection.</p> <p>Args:     partition_key: S3 partition key</p> <p>Returns:     MD5 hash of the partition key</p>"},{"location":"libraries/hoopstat-data/#validate_partition_structure","title":"validate_partition_structure","text":"<pre><code>validate_partition_structure(partition_key: S3PartitionKey) -&gt; Any\n</code></pre> <p>Validate partition structure against ADR-020 standards.</p> <p>Args:     partition_key: S3 partition key to validate</p> <p>Returns:     Validation result with warnings and recommendations</p>"},{"location":"libraries/hoopstat-data/#get_schema_version","title":"get_schema_version","text":"<pre><code>get_schema_version() -&gt; str\n</code></pre> <p>Get current schema version.</p>"},{"location":"libraries/hoopstat-data/#generate_json_schema","title":"generate_json_schema","text":"<pre><code>generate_json_schema(model_class: Any) -&gt; Any\n</code></pre> <p>Generate JSON schema for a Silver layer model.</p>"},{"location":"libraries/hoopstat-data/#validate_field_goals","title":"validate_field_goals","text":"<pre><code>validate_field_goals(cls, v, info) -&gt; Any\n</code></pre> <p>Ensure field goals attempted &gt;= field goals made.</p>"},{"location":"libraries/hoopstat-data/#validate_points_range","title":"validate_points_range","text":"<pre><code>validate_points_range(cls, v, info) -&gt; Any\n</code></pre> <p>Validate points are within reasonable NBA game ranges.</p>"},{"location":"libraries/hoopstat-data/#validate_player_name","title":"validate_player_name","text":"<pre><code>validate_player_name(cls, v) -&gt; Any\n</code></pre> <p>Ensure player name is properly formatted.</p>"},{"location":"libraries/hoopstat-data/#validate_shooting_consistency","title":"validate_shooting_consistency","text":"<pre><code>validate_shooting_consistency(self) -&gt; Any\n</code></pre> <p>Validate shooting statistics consistency.</p>"},{"location":"libraries/hoopstat-data/#validate_team_name","title":"validate_team_name","text":"<pre><code>validate_team_name(cls, v) -&gt; Any\n</code></pre> <p>Ensure team name is valid NBA team.</p>"},{"location":"libraries/hoopstat-data/#validate_points_range_1","title":"validate_points_range","text":"<pre><code>validate_points_range(cls, v, info) -&gt; Any\n</code></pre> <p>Validate team points are within reasonable NBA game ranges.</p>"},{"location":"libraries/hoopstat-data/#validate_team_shooting_stats","title":"validate_team_shooting_stats","text":"<pre><code>validate_team_shooting_stats(self) -&gt; Any\n</code></pre> <p>Validate team shooting statistics consistency.</p>"},{"location":"libraries/hoopstat-data/#validate_game_date","title":"validate_game_date","text":"<pre><code>validate_game_date(cls, v) -&gt; Any\n</code></pre> <p>Ensure game date is in ISO format if provided.</p>"},{"location":"libraries/hoopstat-data/#validate_season_format_1","title":"validate_season_format","text":"<pre><code>validate_season_format(cls, v) -&gt; Any\n</code></pre> <p>Validate NBA season format (e.g., '2023-24').</p>"},{"location":"libraries/hoopstat-data/#validate_game_logic","title":"validate_game_logic","text":"<pre><code>validate_game_logic(self) -&gt; Any\n</code></pre> <p>Validate game logic and constraints.</p>"},{"location":"libraries/hoopstat-data/#validate_ts_percentage","title":"validate_ts_percentage","text":"<pre><code>validate_ts_percentage(cls, v) -&gt; Any\n</code></pre> <p>Validate true shooting percentage is reasonable.</p>"},{"location":"libraries/hoopstat-data/#validate_season_format_2","title":"validate_season_format","text":"<pre><code>validate_season_format(cls, v) -&gt; Any\n</code></pre> <p>Validate NBA season format.</p>"},{"location":"libraries/hoopstat-data/#validate_season_format_3","title":"validate_season_format","text":"<pre><code>validate_season_format(cls, v) -&gt; Any\n</code></pre> <p>Validate NBA season format.</p>"},{"location":"libraries/hoopstat-data/#migrate_from_version","title":"migrate_from_version","text":"<pre><code>migrate_from_version(data: Any, from_version: str, to_version: str) -&gt; Any\n</code></pre> <p>Migrate data from one schema version to another.</p>"},{"location":"libraries/hoopstat-data/#examples","title":"Examples","text":""},{"location":"libraries/hoopstat-data/#normalize_team_name_1","title":"normalize_team_name","text":"<pre><code>&gt;&gt;&gt; normalize_team_name(\"lakers\")\n</code></pre>"},{"location":"libraries/hoopstat-data/#calculate_efficiency_rating_1","title":"calculate_efficiency_rating","text":"<pre><code>&gt;&gt;&gt; stats = {\n...     \"points\": 25, \"rebounds\": 10, \"assists\": 5,\n...     \"steals\": 2, \"blocks\": 1, \"turnovers\": 3, \"minutes_played\": 35\n... }\n&gt;&gt;&gt; calculate_efficiency_rating(stats)\n</code></pre>"},{"location":"libraries/hoopstat-data/#standardize_position_2","title":"standardize_position","text":"<pre><code>&gt;&gt;&gt; standardize_position(\"Point Guard\")\n</code></pre>"},{"location":"libraries/hoopstat-data/#calculate_shooting_percentage_1","title":"calculate_shooting_percentage","text":"<pre><code>&gt;&gt;&gt; calculate_shooting_percentage(8, 15)\n</code></pre>"},{"location":"libraries/hoopstat-data/#convert_minutes_to_decimal_1","title":"convert_minutes_to_decimal","text":"<pre><code>&gt;&gt;&gt; convert_minutes_to_decimal(\"35:30\")\n</code></pre>"},{"location":"libraries/hoopstat-data/#normalize_stat_per_game_1","title":"normalize_stat_per_game","text":"<pre><code>&gt;&gt;&gt; normalize_stat_per_game(250, 10)\n</code></pre>"},{"location":"libraries/hoopstat-data/#clean_and_transform_record_1","title":"clean_and_transform_record","text":"<pre><code>&gt;&gt;&gt; record = {\"team_name\": \"lakers\", \"points\": \"25\", \"position\": \"point guard\"}\n&gt;&gt;&gt; clean_and_transform_record(record)\n</code></pre>"},{"location":"libraries/hoopstat-data/#clean_batch_1","title":"clean_batch","text":"<pre><code>&gt;&gt;&gt; records = [{\"team_name\": \"lakers\"}, {\"team_name\": \"warriors\"}]\n&gt;&gt;&gt; clean_batch(records)\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_and_standardize_season_1","title":"validate_and_standardize_season","text":"<pre><code>&gt;&gt;&gt; validate_and_standardize_season(\"2023-2024\")\n</code></pre>"},{"location":"libraries/hoopstat-data/#check_data_completeness_1","title":"check_data_completeness","text":"<pre><code>&gt;&gt;&gt; data = {\"points\": 25, \"rebounds\": None, \"assists\": 5}\n&gt;&gt;&gt; result = check_data_completeness(data)  # doctest: +SKIP\n</code></pre>"},{"location":"libraries/hoopstat-data/#detect_outliers_1","title":"detect_outliers","text":"<pre><code>&gt;&gt;&gt; values = [10, 12, 11, 13, 15, 50, 14]\n&gt;&gt;&gt; detect_outliers(values)\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_stat_consistency_1","title":"validate_stat_consistency","text":"<pre><code>&gt;&gt;&gt; stats = [\n...     {\"player_id\": \"123\", \"points\": 25, \"field_goals_made\": 10},\n...     {\"player_id\": \"123\", \"points\": -5, \"field_goals_made\": 15}\n... ]\n&gt;&gt;&gt; issues = validate_stat_consistency(stats)  # doctest: +SKIP\n</code></pre>"},{"location":"libraries/hoopstat-data/#calculate_data_quality_score_1","title":"calculate_data_quality_score","text":"<pre><code>&gt;&gt;&gt; data = {\"points\": 25, \"rebounds\": 10, \"assists\": 5}\n&gt;&gt;&gt; calculate_data_quality_score(data)\n</code></pre>"},{"location":"libraries/hoopstat-data/#identify_missing_critical_stats_1","title":"identify_missing_critical_stats","text":"<pre><code>&gt;&gt;&gt; data = {\"rebounds\": 10, \"assists\": 5}\n&gt;&gt;&gt; identify_missing_critical_stats(data)\n</code></pre>"},{"location":"libraries/hoopstat-data/#compare_stat_distributions_1","title":"compare_stat_distributions","text":"<pre><code>&gt;&gt;&gt; data1 = [{\"points\": 20}, {\"points\": 25}]\n&gt;&gt;&gt; data2 = [{\"points\": 15}, {\"points\": 30}]\n&gt;&gt;&gt; compare_stat_distributions(data1, data2, \"points\")\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_player_stats_1","title":"validate_player_stats","text":"<pre><code>&gt;&gt;&gt; stats = {\"points\": 25, \"rebounds\": 10, \"assists\": 5}\n&gt;&gt;&gt; validate_player_stats(stats)\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_team_stats_1","title":"validate_team_stats","text":"<pre><code>&gt;&gt;&gt; stats = {\"team_name\": \"Lakers\", \"points\": 120, \"field_goals_made\": 45}\n&gt;&gt;&gt; validate_team_stats(stats)\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_game_stats_1","title":"validate_game_stats","text":"<pre><code>&gt;&gt;&gt; stats = {\"home_score\": 110, \"away_score\": 105, \"game_id\": \"game_123\"}\n&gt;&gt;&gt; validate_game_stats(stats)\n</code></pre>"},{"location":"libraries/hoopstat-data/#validate_stat_ranges_1","title":"validate_stat_ranges","text":"<pre><code>&gt;&gt;&gt; stats = {\"points\": 25, \"rebounds\": -5}\n&gt;&gt;&gt; validate_stat_ranges(stats)\n</code></pre>"},{"location":"libraries/hoopstat-e2e-testing/","title":"hoopstat-e2e-testing","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/hoopstat-e2e-testing/#description","title":"Description","text":"<p>End-to-end testing utilities for basketball data pipeline.</p> <p>This package provides utilities for testing the complete data pipeline using Localstack S3 simulation and Docker Compose orchestration.</p>"},{"location":"libraries/hoopstat-e2e-testing/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nhoopstat-e2e-testing = {path = \"../libs/hoopstat-e2e-testing\", develop = true}\n</code></pre>"},{"location":"libraries/hoopstat-e2e-testing/#usage","title":"Usage","text":"<pre><code>from hoopstat_e2e_testing import S3TestUtils, PipelineTestRunner, LocalstackManager\n</code></pre>"},{"location":"libraries/hoopstat-e2e-testing/#api-reference","title":"API Reference","text":""},{"location":"libraries/hoopstat-e2e-testing/#classes","title":"Classes","text":""},{"location":"libraries/hoopstat-e2e-testing/#localstackmanager","title":"LocalstackManager","text":"<p>Manages Localstack container for testing.</p> <p>Methods:</p> <ul> <li><code>start(self, timeout: int) -&gt; bool</code></li> <li>Start Localstack container.</li> <li><code>stop(self) -&gt; bool</code></li> <li>Stop and remove Localstack container.</li> <li><code>wait_for_ready(self, timeout: int) -&gt; bool</code></li> <li>Wait for Localstack to be ready to accept requests.</li> <li><code>is_running(self) -&gt; bool</code></li> <li>Check if Localstack container is running.</li> <li><code>get_logs(self) -&gt; str</code></li> <li>Get logs from Localstack container.</li> </ul>"},{"location":"libraries/hoopstat-e2e-testing/#pipelinetestrunner","title":"PipelineTestRunner","text":"<p>Orchestrates end-to-end pipeline testing.</p> <p>Methods:</p> <ul> <li><code>setup_environment(self) -&gt; bool</code></li> <li>Set up the testing environment with medallion architecture buckets.</li> <li><code>cleanup_environment(self) -&gt; bool</code></li> <li>Clean up the testing environment.</li> <li><code>ingest_bronze_data(self, num_teams: int, num_players_per_team: int) -&gt; bool</code></li> <li>Ingest raw mock data into the bronze layer.</li> <li><code>transform_silver_data(self) -&gt; bool</code></li> <li>Transform bronze data into silver layer (cleaned and normalized).</li> <li><code>aggregate_gold_data(self) -&gt; bool</code></li> <li>Aggregate silver data into gold layer (business metrics).</li> <li><code>run_full_pipeline(self, num_teams: int, num_players_per_team: int) -&gt; bool</code></li> <li>Run the complete pipeline test from bronze to gold.</li> <li><code>verify_pipeline_output(self) -&gt; Any</code></li> <li>Verify the pipeline output and return validation results.</li> </ul>"},{"location":"libraries/hoopstat-e2e-testing/#datetimeencoder","title":"DateTimeEncoder","text":"<p>Custom JSON encoder that handles datetime objects.</p> <p>Methods:</p> <ul> <li><code>default(self, obj) -&gt; Any</code></li> </ul>"},{"location":"libraries/hoopstat-e2e-testing/#s3testutils","title":"S3TestUtils","text":"<p>Utilities for S3 operations during testing with Localstack.</p> <p>Methods:</p> <ul> <li><code>create_bucket(self, bucket_name: str) -&gt; bool</code></li> <li>Create an S3 bucket.</li> <li><code>delete_bucket(self, bucket_name: str, delete_objects: bool) -&gt; bool</code></li> <li>Delete an S3 bucket.</li> <li><code>bucket_exists(self, bucket_name: str) -&gt; bool</code></li> <li>Check if a bucket exists.</li> <li><code>put_object(self, bucket_name: str, key: str, data: Any, content_type: Any) -&gt; bool</code></li> <li>Put an object in S3.</li> <li><code>get_object(self, bucket_name: str, key: str, return_type: str) -&gt; Any</code></li> <li>Get an object from S3.</li> <li><code>delete_object(self, bucket_name: str, key: str) -&gt; bool</code></li> <li>Delete an object from S3.</li> <li><code>list_objects(self, bucket_name: str, prefix: str) -&gt; Any</code></li> <li>List objects in a bucket.</li> <li><code>cleanup_test_buckets(self, prefix: str) -&gt; None</code></li> <li>Clean up all test buckets with a given prefix.</li> <li><code>setup_medallion_buckets(self, project_name: str) -&gt; Any</code></li> <li>Set up bronze, silver, and gold buckets for medallion architecture testing.</li> </ul>"},{"location":"libraries/hoopstat-e2e-testing/#functions","title":"Functions","text":""},{"location":"libraries/hoopstat-e2e-testing/#start","title":"start","text":"<pre><code>start(self, timeout: int) -&gt; bool\n</code></pre> <p>Start Localstack container.</p> <p>Args:     timeout: Maximum time to wait for container to be ready</p> <p>Returns:     True if container started successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#stop","title":"stop","text":"<pre><code>stop(self) -&gt; bool\n</code></pre> <p>Stop and remove Localstack container.</p> <p>Returns:     True if container stopped successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#wait_for_ready","title":"wait_for_ready","text":"<pre><code>wait_for_ready(self, timeout: int) -&gt; bool\n</code></pre> <p>Wait for Localstack to be ready to accept requests.</p> <p>Args:     timeout: Maximum time to wait in seconds</p> <p>Returns:     True if Localstack is ready, False if timeout</p>"},{"location":"libraries/hoopstat-e2e-testing/#is_running","title":"is_running","text":"<pre><code>is_running(self) -&gt; bool\n</code></pre> <p>Check if Localstack container is running.</p> <p>Returns:     True if container is running, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#get_logs","title":"get_logs","text":"<pre><code>get_logs(self) -&gt; str\n</code></pre> <p>Get logs from Localstack container.</p> <p>Returns:     Container logs as string</p>"},{"location":"libraries/hoopstat-e2e-testing/#setup_environment","title":"setup_environment","text":"<pre><code>setup_environment(self) -&gt; bool\n</code></pre> <p>Set up the testing environment with medallion architecture buckets.</p> <p>Returns:     True if setup successful, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#cleanup_environment","title":"cleanup_environment","text":"<pre><code>cleanup_environment(self) -&gt; bool\n</code></pre> <p>Clean up the testing environment.</p> <p>Returns:     True if cleanup successful, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#ingest_bronze_data","title":"ingest_bronze_data","text":"<pre><code>ingest_bronze_data(self, num_teams: int, num_players_per_team: int) -&gt; bool\n</code></pre> <p>Ingest raw mock data into the bronze layer.</p> <p>Args:     num_teams: Number of teams to generate     num_players_per_team: Number of players per team</p> <p>Returns:     True if ingestion successful, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#transform_silver_data","title":"transform_silver_data","text":"<pre><code>transform_silver_data(self) -&gt; bool\n</code></pre> <p>Transform bronze data into silver layer (cleaned and normalized).</p> <p>Returns:     True if transformation successful, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#aggregate_gold_data","title":"aggregate_gold_data","text":"<pre><code>aggregate_gold_data(self) -&gt; bool\n</code></pre> <p>Aggregate silver data into gold layer (business metrics).</p> <p>Returns:     True if aggregation successful, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#run_full_pipeline","title":"run_full_pipeline","text":"<pre><code>run_full_pipeline(self, num_teams: int, num_players_per_team: int) -&gt; bool\n</code></pre> <p>Run the complete pipeline test from bronze to gold.</p> <p>Args:     num_teams: Number of teams to generate     num_players_per_team: Number of players per team</p> <p>Returns:     True if entire pipeline completed successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#verify_pipeline_output","title":"verify_pipeline_output","text":"<pre><code>verify_pipeline_output(self) -&gt; Any\n</code></pre> <p>Verify the pipeline output and return validation results.</p> <p>Returns:     Dictionary with validation results</p>"},{"location":"libraries/hoopstat-e2e-testing/#default","title":"default","text":"<pre><code>default(self, obj) -&gt; Any\n</code></pre>"},{"location":"libraries/hoopstat-e2e-testing/#create_bucket","title":"create_bucket","text":"<pre><code>create_bucket(self, bucket_name: str) -&gt; bool\n</code></pre> <p>Create an S3 bucket.</p> <p>Args:     bucket_name: Name of the bucket to create</p> <p>Returns:     True if bucket was created successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#delete_bucket","title":"delete_bucket","text":"<pre><code>delete_bucket(self, bucket_name: str, delete_objects: bool) -&gt; bool\n</code></pre> <p>Delete an S3 bucket.</p> <p>Args:     bucket_name: Name of the bucket to delete     delete_objects: Whether to delete all objects in the bucket first</p> <p>Returns:     True if bucket was deleted successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#bucket_exists","title":"bucket_exists","text":"<pre><code>bucket_exists(self, bucket_name: str) -&gt; bool\n</code></pre> <p>Check if a bucket exists.</p> <p>Args:     bucket_name: Name of the bucket to check</p> <p>Returns:     True if bucket exists, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#put_object","title":"put_object","text":"<pre><code>put_object(self, bucket_name: str, key: str, data: Any, content_type: Any) -&gt; bool\n</code></pre> <p>Put an object in S3.</p> <p>Args:     bucket_name: Name of the bucket     key: Object key (path)     data: Data to upload (string, bytes, dict, or DataFrame)     content_type: Content type of the object</p> <p>Returns:     True if object was uploaded successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#get_object","title":"get_object","text":"<pre><code>get_object(self, bucket_name: str, key: str, return_type: str) -&gt; Any\n</code></pre> <p>Get an object from S3.</p> <p>Args:     bucket_name: Name of the bucket     key: Object key (path)     return_type: Type to return data as ('string', 'bytes', 'json', 'dataframe')</p> <p>Returns:     Object data in the specified format, or None if error</p>"},{"location":"libraries/hoopstat-e2e-testing/#delete_object","title":"delete_object","text":"<pre><code>delete_object(self, bucket_name: str, key: str) -&gt; bool\n</code></pre> <p>Delete an object from S3.</p> <p>Args:     bucket_name: Name of the bucket     key: Object key (path)</p> <p>Returns:     True if object was deleted successfully, False otherwise</p>"},{"location":"libraries/hoopstat-e2e-testing/#list_objects","title":"list_objects","text":"<pre><code>list_objects(self, bucket_name: str, prefix: str) -&gt; Any\n</code></pre> <p>List objects in a bucket.</p> <p>Args:     bucket_name: Name of the bucket     prefix: Prefix to filter objects</p> <p>Returns:     List of object information dictionaries</p>"},{"location":"libraries/hoopstat-e2e-testing/#cleanup_test_buckets","title":"cleanup_test_buckets","text":"<pre><code>cleanup_test_buckets(self, prefix: str) -&gt; None\n</code></pre> <p>Clean up all test buckets with a given prefix.</p> <p>Args:     prefix: Prefix to identify test buckets</p>"},{"location":"libraries/hoopstat-e2e-testing/#setup_medallion_buckets","title":"setup_medallion_buckets","text":"<pre><code>setup_medallion_buckets(self, project_name: str) -&gt; Any\n</code></pre> <p>Set up bronze, silver, and gold buckets for medallion architecture testing.</p> <p>Args:     project_name: Project name prefix for buckets</p> <p>Returns:     Dictionary with bucket names for each layer</p>"},{"location":"libraries/hoopstat-mock-data/","title":"hoopstat-mock-data","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/hoopstat-mock-data/#description","title":"Description","text":"<p>Mock NBA data generation framework for testing Hoopstat Haus data pipelines.</p>"},{"location":"libraries/hoopstat-mock-data/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nhoopstat-mock-data = {path = \"../libs/hoopstat-mock-data\", develop = true}\n</code></pre>"},{"location":"libraries/hoopstat-mock-data/#usage","title":"Usage","text":"<pre><code>from hoopstat_mock_data import MockDataGenerator, Team, Player, Game, PlayerStats, TeamStats\n</code></pre>"},{"location":"libraries/hoopstat-mock-data/#api-reference","title":"API Reference","text":""},{"location":"libraries/hoopstat-mock-data/#classes","title":"Classes","text":""},{"location":"libraries/hoopstat-mock-data/#position","title":"Position","text":"<p>Basketball positions.</p>"},{"location":"libraries/hoopstat-mock-data/#conference","title":"Conference","text":"<p>NBA conferences.</p>"},{"location":"libraries/hoopstat-mock-data/#division","title":"Division","text":"<p>NBA divisions.</p>"},{"location":"libraries/hoopstat-mock-data/#gametype","title":"GameType","text":"<p>Types of NBA games.</p>"},{"location":"libraries/hoopstat-mock-data/#team","title":"Team","text":"<p>NBA team model.</p>"},{"location":"libraries/hoopstat-mock-data/#player","title":"Player","text":"<p>NBA player model.</p>"},{"location":"libraries/hoopstat-mock-data/#game","title":"Game","text":"<p>NBA game model.</p>"},{"location":"libraries/hoopstat-mock-data/#playerstats","title":"PlayerStats","text":"<p>Player statistics for a game.</p>"},{"location":"libraries/hoopstat-mock-data/#teamstats","title":"TeamStats","text":"<p>Team statistics for a game.</p>"},{"location":"libraries/hoopstat-mock-data/#functions","title":"Functions","text":""},{"location":"libraries/hoopstat-mock-data/#cli","title":"cli","text":"<pre><code>cli() -&gt; Any\n</code></pre> <p>Mock NBA data generation framework for testing Hoopstat Haus data pipelines.</p>"},{"location":"libraries/hoopstat-mock-data/#generate","title":"generate","text":"<pre><code>generate(teams: int, players_per_team: int, games: int, season: str, include_playoffs: bool, output: str, output_format: str, seed: Any, validate: bool, compress: bool) -&gt; Any\n</code></pre> <p>Generate NBA mock data.</p>"},{"location":"libraries/hoopstat-mock-data/#preset","title":"preset","text":"<pre><code>preset(preset: str, output: str, output_format: str, seed: Any) -&gt; Any\n</code></pre> <p>Generate preset datasets for testing.</p>"},{"location":"libraries/hoopstat-mock-data/#validate","title":"validate","text":"<pre><code>validate(filepath: str, data_type: Any) -&gt; Any\n</code></pre> <p>Validate NBA data against schemas.</p>"},{"location":"libraries/hoopstat-mock-data/#info","title":"info","text":"<pre><code>info(filepath: str) -&gt; Any\n</code></pre> <p>Show information about NBA data file.</p>"},{"location":"libraries/hoopstat-mock-data/#main","title":"main","text":"<pre><code>main() -&gt; Any\n</code></pre> <p>Entry point for the CLI.</p>"},{"location":"libraries/hoopstat-observability/","title":"hoopstat-observability","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/hoopstat-observability/#description","title":"Description","text":"<p>Hoopstat Observability Library</p> <p>Standardized logging and observability utilities for Hoopstat Haus applications. Implements structured JSON logging per ADR-015, CloudWatch integration per ADR-018, and semantic versioning per ADR-016.</p> <p>This library consolidates logging functionality to ensure consistent observability across all applications while eliminating code duplication.</p>"},{"location":"libraries/hoopstat-observability/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\nhoopstat-observability = {path = \"../libs/hoopstat-observability\", develop = true}\n</code></pre>"},{"location":"libraries/hoopstat-observability/#usage","title":"Usage","text":"<pre><code>from hoopstat_observability import JSONLogger, get_logger, performance_monitor, performance_context, CorrelationContext, correlation_context, DiagnosticLogger\n</code></pre>"},{"location":"libraries/hoopstat-observability/#api-reference","title":"API Reference","text":""},{"location":"libraries/hoopstat-observability/#classes","title":"Classes","text":""},{"location":"libraries/hoopstat-observability/#jsonformatter","title":"JSONFormatter","text":"<p>Custom logging formatter that outputs structured JSON logs per ADR-015.</p> <p>Ensures consistent format across all log entries with required fields for CloudWatch metric extraction and observability.</p> <p>Methods:</p> <ul> <li><code>format(self, record: Any) -&gt; str</code></li> <li>Format log record as structured JSON.</li> </ul>"},{"location":"libraries/hoopstat-observability/#jsonlogger","title":"JSONLogger","text":"<p>Standardized logger that outputs structured JSON per ADR-015.</p> <p>Provides convenience methods for common logging patterns and ensures consistent structure across all log entries.</p> <p>Methods:</p> <ul> <li><code>info(self, message: str) -&gt; None</code></li> <li>Log info level message with optional extra fields.</li> <li><code>warning(self, message: str) -&gt; None</code></li> <li>Log warning level message with optional extra fields.</li> <li><code>error(self, message: str) -&gt; None</code></li> <li>Log error level message with optional extra fields.</li> <li><code>debug(self, message: str) -&gt; None</code></li> <li>Log debug level message with optional extra fields.</li> <li><code>critical(self, message: str) -&gt; None</code></li> <li>Log critical level message with optional extra fields.</li> <li><code>log_performance(self, job_name: str, duration_in_seconds: float, records_processed: int, status: str) -&gt; None</code></li> <li>Log performance metrics in ADR-015 standard format.</li> <li><code>log_with_correlation(self, level: str, message: str, correlation_id: Any) -&gt; None</code></li> <li>Log message with correlation ID for request tracing.</li> </ul>"},{"location":"libraries/hoopstat-observability/#diagnosticlogger","title":"DiagnosticLogger","text":"<p>Enhanced logger for debugging and diagnostic information.</p> <p>Provides utilities for capturing system state, performance metrics, and detailed debugging information with structured logging.</p> <p>Methods:</p> <ul> <li><code>log_system_info(self) -&gt; None</code></li> <li>Log system and environment information for diagnostics.</li> <li><code>log_function_entry(self, func_name: str, args: tuple, kwargs: Any) -&gt; None</code></li> <li>Log function entry with parameters for debugging.</li> <li><code>log_function_exit(self, func_name: str, result: Any, duration: Any) -&gt; None</code></li> <li>Log function exit with result information.</li> <li><code>log_exception(self, exception: Exception, context: Any) -&gt; None</code></li> <li>Log exception with full traceback and context.</li> <li><code>log_performance_warning(self, operation: str, duration: float, threshold: float, context: Any) -&gt; None</code></li> <li>Log performance warning when operation exceeds threshold.</li> <li><code>log_memory_usage(self) -&gt; None</code></li> <li>Log current memory usage for diagnostics.</li> <li><code>trace_execution(self, func) -&gt; Any</code></li> <li>Decorator for detailed function execution tracing.</li> </ul>"},{"location":"libraries/hoopstat-observability/#correlationcontext","title":"CorrelationContext","text":"<p>Manages correlation IDs for request tracing.</p> <p>Provides thread-safe storage and retrieval of correlation IDs to enable tracking requests across multiple services and operations.</p> <p>Methods:</p> <ul> <li><code>get_correlation_id() -&gt; Any</code></li> <li>Get the current correlation ID for this thread.</li> <li><code>set_correlation_id(correlation_id: str) -&gt; None</code></li> <li>Set the correlation ID for this thread.</li> <li><code>generate_correlation_id() -&gt; str</code></li> <li>Generate a new UUID-based correlation ID.</li> <li><code>clear_correlation_id() -&gt; None</code></li> <li>Clear the correlation ID for this thread.</li> </ul>"},{"location":"libraries/hoopstat-observability/#functions","title":"Functions","text":""},{"location":"libraries/hoopstat-observability/#get_logger","title":"get_logger","text":"<pre><code>get_logger(name: str, level: int) -&gt; JSONLogger\n</code></pre> <p>Get a standardized JSON logger instance.</p> <p>Args:     name: Logger name (typically name of calling module)     level: Logging level (default: INFO)</p> <p>Returns:     Configured JSONLogger instance</p> <p>Example:     logger = get_logger(name)     logger.info(\"Application started\", version=\"1.0.0\")</p>"},{"location":"libraries/hoopstat-observability/#format","title":"format","text":"<pre><code>format(self, record: Any) -&gt; str\n</code></pre> <p>Format log record as structured JSON.</p> <p>Args:     record: Python logging record to format</p> <p>Returns:     JSON string formatted according to ADR-015 standards</p>"},{"location":"libraries/hoopstat-observability/#info","title":"info","text":"<pre><code>info(self, message: str) -&gt; None\n</code></pre> <p>Log info level message with optional extra fields.</p>"},{"location":"libraries/hoopstat-observability/#warning","title":"warning","text":"<pre><code>warning(self, message: str) -&gt; None\n</code></pre> <p>Log warning level message with optional extra fields.</p>"},{"location":"libraries/hoopstat-observability/#error","title":"error","text":"<pre><code>error(self, message: str) -&gt; None\n</code></pre> <p>Log error level message with optional extra fields.</p>"},{"location":"libraries/hoopstat-observability/#debug","title":"debug","text":"<pre><code>debug(self, message: str) -&gt; None\n</code></pre> <p>Log debug level message with optional extra fields.</p>"},{"location":"libraries/hoopstat-observability/#critical","title":"critical","text":"<pre><code>critical(self, message: str) -&gt; None\n</code></pre> <p>Log critical level message with optional extra fields.</p>"},{"location":"libraries/hoopstat-observability/#log_performance","title":"log_performance","text":"<pre><code>log_performance(self, job_name: str, duration_in_seconds: float, records_processed: int, status: str) -&gt; None\n</code></pre> <p>Log performance metrics in ADR-015 standard format.</p> <p>Args:     job_name: Name of the job or operation     duration_in_seconds: Execution time in seconds     records_processed: Number of records processed     status: Job status (success/failed)     **kwargs: Additional context fields</p>"},{"location":"libraries/hoopstat-observability/#log_with_correlation","title":"log_with_correlation","text":"<pre><code>log_with_correlation(self, level: str, message: str, correlation_id: Any) -&gt; None\n</code></pre> <p>Log message with correlation ID for request tracing.</p> <p>Args:     level: Log level (info, warning, error, debug, critical)     message: Log message     correlation_id: Correlation ID for request tracing     **kwargs: Additional context fields</p>"},{"location":"libraries/hoopstat-observability/#get_diagnostic_logger","title":"get_diagnostic_logger","text":"<pre><code>get_diagnostic_logger(name: str) -&gt; DiagnosticLogger\n</code></pre> <p>Get a diagnostic logger instance.</p> <p>Args:     name: Logger name (typically name of calling module)</p> <p>Returns:     Configured DiagnosticLogger instance</p> <p>Example:     diagnostics = get_diagnostic_logger(name)     diagnostics.log_system_info()</p>"},{"location":"libraries/hoopstat-observability/#log_system_info","title":"log_system_info","text":"<pre><code>log_system_info(self) -&gt; None\n</code></pre> <p>Log system and environment information for diagnostics.</p>"},{"location":"libraries/hoopstat-observability/#log_function_entry","title":"log_function_entry","text":"<pre><code>log_function_entry(self, func_name: str, args: tuple, kwargs: Any) -&gt; None\n</code></pre> <p>Log function entry with parameters for debugging.</p> <p>Args:     func_name: Name of the function being entered     args: Positional arguments (sensitive data will be masked)     kwargs: Keyword arguments (sensitive data will be masked)</p>"},{"location":"libraries/hoopstat-observability/#log_function_exit","title":"log_function_exit","text":"<pre><code>log_function_exit(self, func_name: str, result: Any, duration: Any) -&gt; None\n</code></pre> <p>Log function exit with result information.</p> <p>Args:     func_name: Name of the function being exited     result: Function result (will be summarized, not logged in full)     duration: Function execution duration in seconds</p>"},{"location":"libraries/hoopstat-observability/#log_exception","title":"log_exception","text":"<pre><code>log_exception(self, exception: Exception, context: Any) -&gt; None\n</code></pre> <p>Log exception with full traceback and context.</p> <p>Args:     exception: Exception that occurred     context: Additional context information</p>"},{"location":"libraries/hoopstat-observability/#log_performance_warning","title":"log_performance_warning","text":"<pre><code>log_performance_warning(self, operation: str, duration: float, threshold: float, context: Any) -&gt; None\n</code></pre> <p>Log performance warning when operation exceeds threshold.</p> <p>Args:     operation: Name of the operation     duration: Actual duration in seconds     threshold: Warning threshold in seconds     context: Additional context information</p>"},{"location":"libraries/hoopstat-observability/#log_memory_usage","title":"log_memory_usage","text":"<pre><code>log_memory_usage(self) -&gt; None\n</code></pre> <p>Log current memory usage for diagnostics.</p>"},{"location":"libraries/hoopstat-observability/#trace_execution","title":"trace_execution","text":"<pre><code>trace_execution(self, func) -&gt; Any\n</code></pre> <p>Decorator for detailed function execution tracing.</p> <p>Logs entry, exit, duration, and any exceptions for the decorated function.</p> <p>Example:     @diagnostics.trace_execution     def complex_operation():         # Function implementation         pass</p>"},{"location":"libraries/hoopstat-observability/#wrapper","title":"wrapper","text":"<pre><code>wrapper() -&gt; Any\n</code></pre>"},{"location":"libraries/hoopstat-observability/#performance_monitor","title":"performance_monitor","text":"<pre><code>performance_monitor(job_name: Any, records_processed_key: str) -&gt; Any\n</code></pre> <p>Decorator to monitor data pipeline performance.</p> <p>Automatically logs execution duration and record count in structured JSON format according to ADR-015 standards. The decorated function should return a value that either: 1. Is the record count (if it returns an integer) 2. Is a dict containing the record count under records_processed_key 3. Has a records_processed attribute</p> <p>Args:     job_name: Name of the data pipeline job. If None, uses function name.     records_processed_key: Key to look for record count in return value dict.</p> <p>Returns:     Decorated function that logs performance metrics.</p> <p>Example:     @performance_monitor(job_name=\"user_data_sync\")     def sync_users():         # Process data...         return {\"records_processed\": 1500, \"status\": \"success\"}</p> <pre><code>@performance_monitor()\ndef process_records():\n    # Process data...\n    return 250  # Return record count directly\n</code></pre>"},{"location":"libraries/hoopstat-observability/#performance_context","title":"performance_context","text":"<pre><code>performance_context(job_name: str, records_processed: int) -&gt; Any\n</code></pre> <p>Context manager to monitor data pipeline performance.</p> <p>Automatically logs execution duration and allows dynamic record count tracking. Provides more flexibility than the decorator for complex workflows.</p> <p>Args:     job_name: Name of the data pipeline job.     records_processed: Initial record count (default: 0).</p> <p>Yields:     Context dict with 'records_processed' key that can be updated during execution.</p> <p>Example:     with performance_context(\"data_export\", 0) as ctx:         for batch in get_data_batches():             process_batch(batch)             ctx[\"records_processed\"] += len(batch)</p>"},{"location":"libraries/hoopstat-observability/#decorator","title":"decorator","text":"<pre><code>decorator(func: F) -&gt; F\n</code></pre>"},{"location":"libraries/hoopstat-observability/#wrapper_1","title":"wrapper","text":"<pre><code>wrapper() -&gt; Any\n</code></pre>"},{"location":"libraries/hoopstat-observability/#correlation_context","title":"correlation_context","text":"<pre><code>correlation_context(correlation_id: Any) -&gt; Any\n</code></pre> <p>Context manager for managing correlation IDs.</p> <p>Automatically sets and clears correlation ID for the duration of the context. Generates a new correlation ID if none provided.</p> <p>Args:     correlation_id: Existing correlation ID to use, or None to generate new one</p> <p>Yields:     The correlation ID being used in this context</p> <p>Example:     # Use existing correlation ID     with correlation_context(\"req-123\") as corr_id:         process_request(corr_id)</p> <pre><code># Generate new correlation ID\nwith correlation_context() as corr_id:\n    start_new_operation(corr_id)\n</code></pre>"},{"location":"libraries/hoopstat-observability/#with_correlation","title":"with_correlation","text":"<pre><code>with_correlation(func) -&gt; Any\n</code></pre> <p>Decorator to automatically include correlation ID in function logging.</p> <p>Any logging performed within the decorated function will automatically include the current correlation ID.</p> <p>Example:     @with_correlation     def process_data():         logger.info(\"Processing started\")  # Will include correlation_id</p>"},{"location":"libraries/hoopstat-observability/#get_correlation_id","title":"get_correlation_id","text":"<pre><code>get_correlation_id() -&gt; Any\n</code></pre> <p>Get the current correlation ID for this thread.</p> <p>Returns:     Current correlation ID or None if not set</p>"},{"location":"libraries/hoopstat-observability/#set_correlation_id","title":"set_correlation_id","text":"<pre><code>set_correlation_id(correlation_id: str) -&gt; None\n</code></pre> <p>Set the correlation ID for this thread.</p> <p>Args:     correlation_id: Unique identifier for request correlation</p>"},{"location":"libraries/hoopstat-observability/#generate_correlation_id","title":"generate_correlation_id","text":"<pre><code>generate_correlation_id() -&gt; str\n</code></pre> <p>Generate a new UUID-based correlation ID.</p> <p>Returns:     New correlation ID</p>"},{"location":"libraries/hoopstat-observability/#clear_correlation_id","title":"clear_correlation_id","text":"<pre><code>clear_correlation_id() -&gt; None\n</code></pre> <p>Clear the correlation ID for this thread.</p>"},{"location":"libraries/hoopstat-observability/#wrapper_2","title":"wrapper","text":"<pre><code>wrapper() -&gt; Any\n</code></pre>"},{"location":"libraries/ingestion/","title":"ingestion","text":"<p>Version: 0.1.0</p>"},{"location":"libraries/ingestion/#description","title":"Description","text":"<p>A Python library for ingesting NBA data from the nba-api, converting to Parquet format, and uploading to S3 with proper partitioning and rate limiting.</p>"},{"location":"libraries/ingestion/#installation","title":"Installation","text":"<p>Add to your application's <code>pyproject.toml</code>:</p> <pre><code>[tool.poetry.dependencies]\ningestion = {path = \"../libs/ingestion\", develop = true}\n</code></pre>"}]}